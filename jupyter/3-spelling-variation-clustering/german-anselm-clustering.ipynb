{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# German Anselm Cluster Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import scipy.spatial\n",
    "import sklearn\n",
    "import sklearn.cluster\n",
    "import pandas\n",
    "import collections\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing\n",
    "\n",
    "- Reading in the corpus data\n",
    "- Splitting into historical/original and modernised portion\n",
    "- Creating distance matrix from historical data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT = '../../histnorm/datasets/historical/german/german-anselm.dev.txt'\n",
    "ENCODING = 'utf-8'\n",
    "CORPUS_NAME = 'german-anselm'\n",
    "FILTER = ('\"', \"'\", '#', '.', ',', '(', ')', ';', '—', '/')\n",
    "\n",
    "# Loading input file, which has the original and modernised token in each line separated by a \\t\n",
    "with open(INPUT, 'r', encoding=ENCODING) as infile:\n",
    "    tokens_raw = [line.strip().split('\\t') for line in infile]\n",
    "\n",
    "# Filter out lines with control characters\n",
    "# TODO: remove limit for testing\n",
    "tokens = [token for token in tokens_raw[:250] if token[0] and not token[0].startswith(FILTER)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the original and modernised tokens and types\n",
    "tokens_original = [token[0].lower() for token in tokens]\n",
    "tokens_modernised = [token[1].lower() for token in tokens]\n",
    "\n",
    "types_original = list(set(tokens_original))\n",
    "types_modernised = list(set(tokens_modernised))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Token and hapax count\n",
    "tokens_original_count = collections.Counter(tokens_original)\n",
    "tokens_modernised_count = collections.Counter(tokens_modernised)\n",
    "\n",
    "hapax_original_count = len([val for val in tokens_original_count.values() if val == 1])\n",
    "hapax_modernised_count = len([val for val in tokens_modernised_count.values() if val == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Levenshtein Distance\n",
    "def levenshtein(string1, string2):\n",
    "    if string1 == string2:\n",
    "        return 0\n",
    "\n",
    "    if not string2:\n",
    "        return len(string1)\n",
    "    if not string1:\n",
    "        return len(string2)\n",
    "\n",
    "    rows = len(string1) + 1\n",
    "    cols = len(string2) + 1\n",
    "    dist = [[0 for c in range(cols)] for r in range(rows)]\n",
    "\n",
    "    for j in range(1, rows):\n",
    "        dist[j][0] = j\n",
    "    for i in range(1, cols):\n",
    "        dist[0][i] = i\n",
    "\n",
    "    for col in range(1, cols):\n",
    "        for row in range(1, rows):\n",
    "            cost = 1\n",
    "            if string1[row - 1] == string2[col - 1]:\n",
    "                cost = 0\n",
    "            dist[row][col] = min(dist[row - 1][col] + 1, dist[row][col - 1] + 1, dist[row - 1][col - 1] + cost)\n",
    "\n",
    "    # Enable for Debugging\n",
    "    # print('\\n'.join([''.join(['{:4}'.format(elem) for elem in row]) for row in dist]))\n",
    "    return dist[row][col]\n",
    "\n",
    "assert levenshtein('', '') == 0\n",
    "assert levenshtein('foobar', 'foobar') == 0\n",
    "assert levenshtein('foobar', 'foubar') == 1\n",
    "assert levenshtein('foobar', 'fuubar') == 2\n",
    "assert levenshtein('foobar', 'fuuar') == 3\n",
    "assert levenshtein('foobar', '') == 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jaro Similarily\n",
    "def jaro(string1, string2):\n",
    "\n",
    "    length1 = len(string1)\n",
    "    length2 = len(string2)\n",
    "   \n",
    "    if length1 == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    if string1 == string2:\n",
    "        return 1.0   \n",
    "\n",
    "    match_bound = max(length1, length2) // 2 - 1\n",
    "\n",
    "    matches = 0  \n",
    "    transpositions = 0\n",
    "\n",
    "    flagged_1 = [] \n",
    "    flagged_2 = []\n",
    "\n",
    "    for i in range(length1):\n",
    "        upperbound = min(i + match_bound, length2 - 1)\n",
    "        lowerbound = max(0, i - match_bound)\n",
    "        for j in range(lowerbound, upperbound + 1):\n",
    "            if string1[i] == string2[j] and j not in flagged_2:\n",
    "                matches += 1\n",
    "                flagged_1.append(i)\n",
    "                flagged_2.append(j)\n",
    "                break\n",
    "\n",
    "    flagged_2.sort()\n",
    "\n",
    "    for i, j in zip(flagged_1, flagged_2):\n",
    "        if string1[i] != string2[j]:\n",
    "            transpositions += 1\n",
    "\n",
    "    if matches == 0:\n",
    "        return 0.0\n",
    "\n",
    "    return (1/3 * ( matches / length1 + matches / length2 + (matches - transpositions // 2) / matches))\n",
    "\n",
    "assert jaro('', '') == 0.0\n",
    "assert jaro('foobar', '') == 0.0\n",
    "assert jaro('foobar', 'foobar') == 1.0\n",
    "assert jaro('foobar', 'barfoo') == 0.4444444444444444\n",
    "assert jaro('duane', 'dwayne') == 0.8222222222222222\n",
    "assert jaro('hans', 'gruber') == 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IBM (LCS-Levenshtein Normalized)\n",
    "\n",
    "# Contractor, D., Faruquie, T. A., & Subramaniam, L. V. (2010, August). \n",
    "# Unsupervised cleansing of noisy text. \n",
    "# In Proceedings of the 23rd International Conference on Computational Linguistics:\n",
    "# Posters (pp. 189-196). Association for Computational Linguistics.\n",
    "\n",
    "from itertools import groupby\n",
    "\n",
    "# Longest Common Substring\n",
    "def longest_common_string(string1, string2):\n",
    "    if string1 == string2:\n",
    "        return len(string1)\n",
    "\n",
    "    if not string1 or not string2:\n",
    "        return 0\n",
    "    \n",
    "    rows = len(string1) + 1\n",
    "    cols = len(string2) + 1\n",
    "    table = [[0 for c in range(cols)] for r in range(rows)]\n",
    "\n",
    "    longest = 0\n",
    "    for col in range(cols):\n",
    "        for row in range(rows):\n",
    "            if col == 0 and row == 0:\n",
    "                table[row][col] = 0\n",
    "            if string1[row - 1] == string2[col - 1]:\n",
    "                table[row][col] = table[row - 1][col - 1] + 1\n",
    "                longest = max(longest, table[row][col])\n",
    "            else:\n",
    "                table[row][col] = 0\n",
    "    \n",
    "    return longest\n",
    "\n",
    "assert longest_common_string('', '') == 0\n",
    "assert longest_common_string('foobar', '') == 0\n",
    "assert longest_common_string('foobar', 'foobar') == 6\n",
    "assert longest_common_string('foobar', 'foo') == 3\n",
    "assert longest_common_string('foobar', 'f') == 1\n",
    "\n",
    "\n",
    "def lcs_ratio(string1, string2):\n",
    "    if not string1 or not string2:\n",
    "        return 0.0\n",
    "    ratio = longest_common_string(string1, string2) / len(string1)\n",
    "    return ratio\n",
    "\n",
    "assert lcs_ratio('', '') == 0.0\n",
    "assert lcs_ratio('foo', '') == 0.0\n",
    "assert lcs_ratio('foobar', 'foobar') == 1.0\n",
    "assert lcs_ratio('foo', 'bar') == 0.0\n",
    "assert lcs_ratio('word', 'deoxyribonucleic') == 0.25\n",
    "\n",
    "\n",
    "def consonant_skeleton(string, vowels='aeiouy'):\n",
    "    without_vowels = ''.join([char for char in string if char not in vowels])     \n",
    "    deduplicated_consonants = ''.join(char for char, _ in groupby(without_vowels))\n",
    "    return deduplicated_consonants\n",
    "\n",
    "assert consonant_skeleton('') == ''\n",
    "assert consonant_skeleton('aeio') == ''\n",
    "assert consonant_skeleton('foobar') == 'fbr'\n",
    "assert consonant_skeleton('ffoobbar') == 'fbr'\n",
    "assert consonant_skeleton('barfoobar') == 'brfbr'\n",
    "\n",
    "\n",
    "def ibm_similarity(string1, string2, vowels='aeiouy'):\n",
    "    similarity = lcs_ratio(string1, string2) / (levenshtein (consonant_skeleton(string1, vowels), consonant_skeleton(string2, vowels)) + 1)\n",
    "    return similarity\n",
    "\n",
    "assert ibm_similarity('', '') == 0.0\n",
    "assert ibm_similarity('foobar', '') == 0.0\n",
    "assert ibm_similarity('foobar', 'foobar') == 1.0\n",
    "assert ibm_similarity('foo', 'bar') == 0.0\n",
    "assert ibm_similarity('word', 'deoxyribonucleic') == 0.03125\n",
    "assert ibm_similarity('foobar', 'aeiou') == 0.041666666666666664"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Compute the Pairwise Distance for each Similarity Measure\n",
    "\n",
    "ibm_vowels = 'eiauoyēüÿjūāẏīȳäöōëȯêḡîïôėǖ'\n",
    "\n",
    "types_original_reshaped = np.array(types_original).reshape(-1,1)\n",
    "types_original_pairwise_distance_levenshtein = scipy.spatial.distance.pdist(types_original_reshaped, lambda x,y: levenshtein(str(x[0]),str(y[0])))   \n",
    "types_original_pairwise_distance_jaro = scipy.spatial.distance.pdist(types_original_reshaped, lambda x,y: jaro(str(x[0]),str(y[0])))   \n",
    "types_original_pairwise_distance_ibm = scipy.spatial.distance.pdist(types_original_reshaped, lambda x,y: ibm_similarity(str(x[0]),str(y[0]),ibm_vowels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Transform the Pairwise Distance for each Similarity Measure into full similarity matrix\n",
    "\n",
    "original_distance_matrix_levenshtein = pandas.DataFrame(scipy.spatial.distance.squareform(types_original_pairwise_distance_levenshtein), index=types_original, columns=types_original)\n",
    "original_distance_matrix_jaro = pandas.DataFrame(scipy.spatial.distance.squareform(types_original_pairwise_distance_jaro), index=types_original, columns=types_original)\n",
    "original_distance_matrix_ibm = pandas.DataFrame(scipy.spatial.distance.squareform(types_original_pairwise_distance_ibm), index=types_original, columns=types_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_distance_matrix_levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_distance_matrix_jaro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_distance_matrix_ibm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_expected_n_clusters(model):\n",
    "    return len(model.items())\n",
    "    \n",
    "def eval_expected_avg_cluster_size(model):\n",
    "    \"\"\"\n",
    "    Compute evaluation clustering by \n",
    "    mapping all historical tokens to their modern type\n",
    "    \"\"\"\n",
    "\n",
    "    evaluation_cluster = dict()\n",
    "\n",
    "    for token in model:\n",
    "        hist = token[0].lower()\n",
    "        cont = token[1].lower()\n",
    "        if cont in evaluation_cluster:\n",
    "            evaluation_cluster[cont].append(hist)\n",
    "        else:\n",
    "            evaluation_cluster[cont] = [hist]\n",
    "\n",
    "    # Calculate average cluster size\n",
    "    avg_spelling_variations = sum([len(val) for val in evaluation_cluster.values()]) / len(evaluation_cluster.values())\n",
    "\n",
    "    return avg_spelling_variations\n",
    "\n",
    "def eval_expected_cluster_similarity_stats(model):\n",
    "    \"\"\"\n",
    "    Calculate inter object similarity for evaluation cluster\n",
    "    \"\"\"\n",
    "    \n",
    "    avg_similarities = []\n",
    "\n",
    "    for cluster in model.values():\n",
    "        reshaped = np.array(cluster).reshape(-1,1)\n",
    "        similarity = scipy.spatial.distance.pdist(reshaped, lambda x,y: jaro(str(x[0]),str(y[0])))\n",
    "        avg_similarities.append(np.mean(similarity))\n",
    "\n",
    "    return pandas.DataFrame(\n",
    "        columns=['Expected'],\n",
    "        index=['Mean', 'Median', 'STD', 'VAR'],\n",
    "        data=[\n",
    "            np.nanmean(avg_similarities),\n",
    "            np.nanmedian(avg_similarities),\n",
    "            np.nanstd(avg_similarities),\n",
    "            np.nanvar(avg_similarities)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def eval_expected_largest_clusters(model, n=10):\n",
    "    clusters = list(model.values())\n",
    "    clusters.sort(key=len)    \n",
    "    \n",
    "    c_length = [len(cl) for cl in clusters[-n:]]\n",
    "    c_tokens = [cl for cl in clusters[-n:]]\n",
    "    \n",
    "    return pandas.DataFrame(\n",
    "        data={\n",
    "            'Length': c_length,\n",
    "            'Tokens': c_tokens\n",
    "        }\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def eval_n_clusters(model):\n",
    "    return model.n_clusters_\n",
    "\n",
    "def eval_random_clusters(model, n=10):\n",
    "\n",
    "    rand_clusters = []\n",
    "    for cluster_id in random.choices(np.unique(model.labels_), k=10):\n",
    "        cluster = types_original_reshaped[np.nonzero(model.labels_ == cluster_id)]\n",
    "        rand_clusters.append([item for sublist in cluster for item in sublist])\n",
    "\n",
    "    return pandas.Series(rand_clusters)\n",
    "\n",
    "def eval_largest_clusters(model, n=10):\n",
    "\n",
    "    clusters = []\n",
    "\n",
    "    for cluster_id in np.unique(model.labels_):\n",
    "        cluster = types_original_reshaped[np.nonzero(model.labels_ == cluster_id)]\n",
    "        clusters.append([item for sublist in cluster for item in sublist])\n",
    "    \n",
    "    clusters.sort(key=len)\n",
    "\n",
    "    c_length = [len(cl) for cl in clusters[-n:]]\n",
    "    c_tokens = [cl for cl in clusters[-n:]]\n",
    "    \n",
    "    return pandas.DataFrame(\n",
    "        data={\n",
    "            'Length': c_length,\n",
    "            'Tokens': c_tokens\n",
    "        }\n",
    "    )\n",
    "\n",
    "def eval_cluster_similarity_stats(model):\n",
    "    \"\"\"\n",
    "    Calculate inter object similarity\n",
    "    \"\"\"\n",
    "\n",
    "    avg_similarities = []\n",
    "    for cluster_id in np.unique(model.labels_):\n",
    "        cluster = types_original_reshaped[np.nonzero(model.labels_ == cluster_id)]\n",
    "        similarity = scipy.spatial.distance.pdist(cluster, lambda x,y: jaro(str(x[0]),str(y[0])))\n",
    "        avg_similarities.append(np.mean(similarity))\n",
    "\n",
    "    return pandas.DataFrame(\n",
    "        columns=['Actual'],\n",
    "        index=['Mean', 'Median', 'STD', 'VAR'],\n",
    "        data=[\n",
    "            np.nanmean(avg_similarities),\n",
    "            np.nanmedian(avg_similarities),\n",
    "            np.nanstd(avg_similarities),\n",
    "            np.nanvar(avg_similarities)\n",
    "        ]\n",
    "    )\n",
    "\n",
    "def eval_avg_cluster_size(model):\n",
    "    print('TODO')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Affinity Propagation Clustering\n",
    "\n",
    "- Damping factor (between 0.5 and 1) is the extent to which the current value is maintained relative to incoming values (weighted 1 - damping). \n",
    "- This in order to avoid numerical oscillations when updating these values (messages)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "damping_factor = 0.5\n",
    "affinity_levenshtein_euclidean = sklearn.cluster.AffinityPropagation(\n",
    "    affinity='euclidean', \n",
    "    damping=damping_factor, \n",
    "    random_state=None).fit(original_distance_matrix_levenshtein)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "- Manual Clustering with AVG Inter-Cluster Similarity as comparison\n",
    "- Number of Clusters in AHC == Type Count (modern)\n",
    "- Avg Spelling variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sklearn.metrics.silhouette_score(original_distance_matrix_levenshtein, \n",
    "                                 affinity_levenshtein_euclidean.labels_, \n",
    "                                 metric='euclidean')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Agglomerative Hierarchical Clustering\n",
    "\n",
    "- linkage distance threshold above which, clusters will not be merged. \n",
    "- If not None, n_clusters must be None and compute_full_tree must be True.\n",
    "- Metric used to compute the linkage. Can be “euclidean”, “l1”, “l2”, “manhattan”, “cosine”, or “precomputed”. \n",
    "- If linkage is “ward”, only “euclidean” is accepted. \n",
    "- If “precomputed”, a distance matrix (instead of a similarity matrix) is needed as input for the fit method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Parameters\n",
    "linkage_method = 'single'\n",
    "distance_threshold = 2\n",
    "\n",
    "# Calculation\n",
    "ahc_levenshtein_single = sklearn.cluster.AgglomerativeClustering(\n",
    "    n_clusters=None, \n",
    "    distance_threshold=distance_threshold, \n",
    "    affinity='precomputed', \n",
    "    linkage=linkage_method).fit(original_distance_matrix_levenshtein)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_random_clusters(ahc_levenshtein_single)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "- Manual Clustering with AVG Inter-Cluster Similarity as comparison\n",
    "- Number of Clusters in AHC == Type Count (modern)\n",
    "- Avg Spelling variations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_n_clusters = eval_expected_n_clusters(evaluation_cluster)\n",
    "expected_n_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_avg_cluster_size = eval_expected_avg_cluster_size(tokens)\n",
    "expected_avg_cluster_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_stats = eval_expected_cluster_similarity_stats(evaluation_cluster)\n",
    "expected_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "expected_largest_clusters = eval_expected_largest_clusters(evaluation_cluster)\n",
    "expected_largest_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_n_clusters = eval_n_clusters(ahc_levenshtein_single)\n",
    "actual_n_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_avg_cluster_size = eval_avg_cluster_size(ahc_levenshtein_single)\n",
    "actual_avg_cluster_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_stats = eval_cluster_similarity_stats(ahc_levenshtein_single)\n",
    "actual_stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_largest_clusters = eval_largest_clusters(ahc_levenshtein_single)\n",
    "actual_largest_clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pandas.concat([actual_stats,expected_stats], axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## JSON Export"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_nodes(node, parent):\n",
    "    \"\"\"\n",
    "    Recursively build tree as dict\n",
    "    \"\"\"\n",
    "\n",
    "    new_node = dict(node_id=node.id, children=[], distance=node.dist)\n",
    "    parent['children'].append(new_node)\n",
    "    if node.left: add_nodes(node.left, new_node)\n",
    "    if node.right: add_nodes(node.right, new_node)\n",
    "\n",
    "def add_labels(node):\n",
    "    \"\"\"\n",
    "    Recursively add labels to the tree\n",
    "    \"\"\"\n",
    "    is_leaf = len(node['children']) == 0\n",
    "\n",
    "    if is_leaf:\n",
    "        node['name'] = labels[node['node_id']]\n",
    "    else:\n",
    "        list(map(add_labels, node['children']))\n",
    "    del node['node_id']\n",
    "\n",
    "if not os.path.exists(CORPUS_NAME + '-cluster-original.json'):\n",
    "    # Transforming Cluster into JSON Tree,\n",
    "    scipy_tree = scipy.cluster.hierarchy.to_tree(original_clustering, rd=False)\n",
    "    tree = dict(name='root', children=[], distance=scipy_tree.dist)\n",
    "\n",
    "    add_nodes(scipy_tree, tree)\n",
    "    add_labels(tree['children'][0])\n",
    "\n",
    "    with open(CORPUS_NAME + '-cluster-original.json', 'w') as clustering:\n",
    "        dump(tree, clustering, indent=1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
