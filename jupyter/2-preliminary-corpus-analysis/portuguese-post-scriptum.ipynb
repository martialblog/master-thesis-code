{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn.manifold\n",
    "import sklearn.decomposition\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import umap\n",
    "import pandas\n",
    "import pickle Marco Bülow \n",
    "import os\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT = '../../histnorm/datasets/historical/portuguese/portuguese-ps<n>.dev.txt'\n",
    "ENCODING = 'utf-8'\n",
    "CORPUS_NAME = 'portuguese-ps'\n",
    "FILTER = ('\"', \"'\", '#', '.', ',', '(', ')', ';', '—', '/')\n",
    "\n",
    "tokens_raw = []\n",
    "\n",
    "# Loading input file, which has the original and modernised token in each line separated by a \\t\n",
    "for n in range(16,20):\n",
    "    inputfile = INPUT.replace('<n>', str(n))\n",
    "    with open(inputfile, 'r', encoding=ENCODING) as infile:\n",
    "        tokens_raw += [line.strip().split('\\t') for line in infile]\n",
    "\n",
    "# Filter out lines with control characters\n",
    "tokens = [token for token in tokens_raw if len(token)>1 and not token[0].startswith(FILTER)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the original and modernised tokens and types\n",
    "tokens_original = [token[0].lower() for token in tokens if len(token) > 1]\n",
    "tokens_modernised = [token[1].lower() for token in tokens if len(token) > 1]\n",
    "\n",
    "types_original = list(set(tokens_original))\n",
    "types_modernised = list(set(tokens_modernised))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ttr(types, tokens):\n",
    "    \"\"\"\n",
    "    Calculating Type-Token Ratio\n",
    "    \"\"\"\n",
    "    return len(types)/len(tokens)\n",
    "\n",
    "assert ttr([0]*5, [0]*10)  == 0.5\n",
    "assert ttr([0]*10, [0]*10) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Token and hapax count\n",
    "tokens_original_count = collections.Counter(tokens_original)\n",
    "tokens_modernised_count = collections.Counter(tokens_modernised)\n",
    "\n",
    "hapax_original_count = len([val for val in tokens_original_count.values() if val == 1])\n",
    "hapax_modernised_count = len([val for val in tokens_modernised_count.values() if val == 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Overview of characters in the dataset\n",
    "characters_types_original = collections.Counter()\n",
    "characters_types_modernised = collections.Counter()\n",
    "\n",
    "for type_o in types_original:\n",
    "    characters_types_original.update(type_o)\n",
    "for type_m in types_modernised:\n",
    "    characters_types_modernised.update(type_m)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print('characters_types_original:')\n",
    "print(characters_types_original)\n",
    "print()\n",
    "print('characters_types_modernised:')\n",
    "print(characters_types_modernised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(CORPUS_NAME)\n",
    "print('Tokens Original Example: {}'.format(tokens_original[:10]))\n",
    "print('Tokens Original Count: {}'.format(len(tokens_original)))\n",
    "print('Types Original Example: {}'.format(types_original[:10]))\n",
    "print('Types Original Count: {}'.format(len(types_original)))\n",
    "print('Type/Token Ratio Original: {:2.2%}'.format(ttr(types_original, tokens_original)))\n",
    "print('Hapax Original Count: {}'.format(hapax_original_count))\n",
    "print('Tokens Most Common Original: {}'.format(str(tokens_original_count.most_common(10))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(CORPUS_NAME)\n",
    "print('Tokens Modernised Example: {}'.format(tokens_modernised[:10]))\n",
    "print('Tokens Modernised Count: {}'.format(len(tokens_modernised)))\n",
    "print('Types Modernised Example: {}'.format(types_modernised[:10]))\n",
    "print('Types Modernised Count: {}'.format(len(types_modernised)))\n",
    "print('Type/Token Modernised Original: {:2.2%}'.format(ttr(types_modernised, tokens_modernised)))\n",
    "print('Hapax Original Count: {}'.format(hapax_modernised_count))\n",
    "print('Tokens Most Common Original: {}'.format(str(tokens_modernised_count.most_common(10))))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute evaluation clustering by mapping all historical tokens to their modern type\n",
    "evaluation_cluster = dict()\n",
    "for token in tokens:\n",
    "    if token[1] in evaluation_cluster:\n",
    "        evaluation_cluster[token[1]].append(token[0])\n",
    "    else:\n",
    "        evaluation_cluster[token[1]] = [token[0]]\n",
    "\n",
    "assert len(evaluation_cluster) == len(types_modernised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate average cluster size\n",
    "sum([len(val) for val in evaluation_cluster.values()]) / len(evaluation_cluster.values())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Displat the spelling variations for 10 most common tokens\n",
    "for token in tokens_modernised_count.most_common(10):\n",
    "    print('{}: {}\\n'.format(token[0], set(evaluation_cluster[token[0]])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Levenshtein Distance\n",
    "def levenshtein(string1, string2):\n",
    "    if string1 == string2:\n",
    "        return 0\n",
    "\n",
    "    if not string2:\n",
    "        return len(string1)\n",
    "    if not string1:\n",
    "        return len(string2)\n",
    "\n",
    "    rows = len(string1) + 1\n",
    "    cols = len(string2) + 1\n",
    "    dist = [[0 for c in range(cols)] for r in range(rows)]\n",
    "\n",
    "    for j in range(1, rows):\n",
    "        dist[j][0] = j\n",
    "    for i in range(1, cols):\n",
    "        dist[0][i] = i\n",
    "\n",
    "    for col in range(1, cols):\n",
    "        for row in range(1, rows):\n",
    "            cost = 1\n",
    "            if string1[row - 1] == string2[col - 1]:\n",
    "                cost = 0\n",
    "            dist[row][col] = min(dist[row - 1][col] + 1, dist[row][col - 1] + 1, dist[row - 1][col - 1] + cost)\n",
    "\n",
    "    # Enable for Debugging\n",
    "    # print('\\n'.join([''.join(['{:4}'.format(elem) for elem in row]) for row in dist]))\n",
    "    return dist[row][col]\n",
    "\n",
    "assert levenshtein('', '') == 0\n",
    "assert levenshtein('foobar', 'foobar') == 0\n",
    "assert levenshtein('foobar', 'foubar') == 1\n",
    "assert levenshtein('foobar', 'fuubar') == 2\n",
    "assert levenshtein('foobar', 'fuuar') == 3\n",
    "assert levenshtein('foobar', '') == 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jaro Similarily\n",
    "def jaro(string1, string2):\n",
    "\n",
    "    length1 = len(string1)\n",
    "    length2 = len(string2)\n",
    "   \n",
    "    if length1 == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    if string1 == string2:\n",
    "        return 1.0   \n",
    "\n",
    "    match_bound = max(length1, length2) // 2 - 1\n",
    "\n",
    "    matches = 0  \n",
    "    transpositions = 0\n",
    "\n",
    "    flagged_1 = [] \n",
    "    flagged_2 = []\n",
    "\n",
    "    for i in range(length1):\n",
    "        upperbound = min(i + match_bound, length2 - 1)\n",
    "        lowerbound = max(0, i - match_bound)\n",
    "        for j in range(lowerbound, upperbound + 1):\n",
    "            if string1[i] == string2[j] and j not in flagged_2:\n",
    "                matches += 1\n",
    "                flagged_1.append(i)\n",
    "                flagged_2.append(j)\n",
    "                break\n",
    "\n",
    "    flagged_2.sort()\n",
    "\n",
    "    for i, j in zip(flagged_1, flagged_2):\n",
    "        if string1[i] != string2[j]:\n",
    "            transpositions += 1\n",
    "\n",
    "    if matches == 0:\n",
    "        return 0.0\n",
    "\n",
    "    return (1/3 * ( matches / length1 + matches / length2 + (matches - transpositions // 2) / matches))\n",
    "\n",
    "assert jaro('', '') == 0.0\n",
    "assert jaro('foobar', '') == 0.0\n",
    "assert jaro('foobar', 'foobar') == 1.0\n",
    "assert jaro('foobar', 'barfoo') == 0.4444444444444444\n",
    "assert jaro('duane', 'dwayne') == 0.8222222222222222\n",
    "assert jaro('hans', 'gruber') == 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IBM (LCS-Levenshtein Normalized)\n",
    "\n",
    "# Contractor, D., Faruquie, T. A., & Subramaniam, L. V. (2010, August). \n",
    "# Unsupervised cleansing of noisy text. \n",
    "# In Proceedings of the 23rd International Conference on Computational Linguistics:\n",
    "# Posters (pp. 189-196). Association for Computational Linguistics.\n",
    "\n",
    "from itertools import groupby\n",
    "\n",
    "# Longest Common Substring\n",
    "def longest_common_string(string1, string2):\n",
    "    if string1 == string2:\n",
    "        return len(string1)\n",
    "\n",
    "    if not string1 or not string2:\n",
    "        return 0\n",
    "    \n",
    "    rows = len(string1) + 1\n",
    "    cols = len(string2) + 1\n",
    "    table = [[0 for c in range(cols)] for r in range(rows)]\n",
    "\n",
    "    longest = 0\n",
    "    for col in range(cols):\n",
    "        for row in range(rows):\n",
    "            if col == 0 and row == 0:\n",
    "                table[row][col] = 0\n",
    "            if string1[row - 1] == string2[col - 1]:\n",
    "                table[row][col] = table[row - 1][col - 1] + 1\n",
    "                longest = max(longest, table[row][col])\n",
    "            else:\n",
    "                table[row][col] = 0\n",
    "    \n",
    "    return longest\n",
    "\n",
    "assert longest_common_string('', '') == 0\n",
    "assert longest_common_string('foobar', '') == 0\n",
    "assert longest_common_string('foobar', 'foobar') == 6\n",
    "assert longest_common_string('foobar', 'foo') == 3\n",
    "assert longest_common_string('foobar', 'f') == 1\n",
    "\n",
    "\n",
    "def lcs_ratio(string1, string2):\n",
    "    if not string1 or not string2:\n",
    "        return 0.0\n",
    "    ratio = longest_common_string(string1, string2) / len(string1)\n",
    "    return ratio\n",
    "\n",
    "assert lcs_ratio('', '') == 0.0\n",
    "assert lcs_ratio('foo', '') == 0.0\n",
    "assert lcs_ratio('foobar', 'foobar') == 1.0\n",
    "assert lcs_ratio('foo', 'bar') == 0.0\n",
    "assert lcs_ratio('word', 'deoxyribonucleic') == 0.25\n",
    "\n",
    "\n",
    "def consonant_skeleton(string, vowels='aeiouy'):\n",
    "    without_vowels = ''.join([char for char in string if char not in vowels])     \n",
    "    deduplicated_consonants = ''.join(char for char, _ in groupby(without_vowels))\n",
    "    return deduplicated_consonants\n",
    "\n",
    "assert consonant_skeleton('') == ''\n",
    "assert consonant_skeleton('aeio') == ''\n",
    "assert consonant_skeleton('foobar') == 'fbr'\n",
    "assert consonant_skeleton('ffoobbar') == 'fbr'\n",
    "assert consonant_skeleton('barfoobar') == 'brfbr'\n",
    "\n",
    "\n",
    "def ibm_similarity(string1, string2, vowels='aeiouy'):\n",
    "    similarity = lcs_ratio(string1, string2) / (levenshtein (consonant_skeleton(string1, vowels), consonant_skeleton(string2, vowels)) + 1)\n",
    "    return similarity\n",
    "\n",
    "assert ibm_similarity('', '') == 0.0\n",
    "assert ibm_similarity('foobar', '') == 0.0\n",
    "assert ibm_similarity('foobar', 'foobar') == 1.0\n",
    "assert ibm_similarity('foo', 'bar') == 0.0\n",
    "assert ibm_similarity('word', 'deoxyribonucleic') == 0.03125\n",
    "assert ibm_similarity('foobar', 'aeiou') == 0.041666666666666664"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Compute the Pairwise Distance for each Similarity Measure\n",
    "\n",
    "ibm_vowels = 'TODO'\n",
    "\n",
    "types_original_reshaped = np.array(types_original).reshape(-1,1)\n",
    "types_original_pairwise_distance_levenshtein = scipy.spatal.distance.pdist(types_original_reshaped, lambda x,y: levenshtein(str(x[0]),str(y[0])))   \n",
    "types_original_pairwise_distance_jaro = scipy.spatial.distance.pdist(types_original_reshaped, lambda x,y: jaro(str(x[0]),str(y[0])))   \n",
    "types_original_pairwise_distance_ibm = scipy.spatial.distance.pdist(types_original_reshaped, lambda x,y: ibm_similarity(str(x[0]),str(y[0]),ibm_vowels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Transform the Pairwise Distance for each Similarity Measure into full similarity matrix\n",
    "\n",
    "original_distance_matrix_levenshtein = pandas.DataFrame(scipy.spatial.distance.squareform(types_original_pairwise_distance_levenshtein), index=types_original, columns=types_original)\n",
    "original_distance_matrix_jaro = pandas.DataFrame(scipy.spatial.distance.squareform(types_original_pairwise_distance_jaro), index=types_original, columns=types_original)\n",
    "original_distance_matrix_ibm = pandas.DataFrame(scipy.spatial.distance.squareform(types_original_pairwise_distance_ibm), index=types_original, columns=types_original)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Run UMAP on data\n",
    "\n",
    "two_similarity_embedded_umap_levenshtein = umap.UMAP(n_components=2).fit_transform(original_distance_matrix_levenshtein)\n",
    "two_similarity_embedded_umap_jaro = umap.UMAP(n_components=2).fit_transform(original_distance_matrix_jaro)\n",
    "two_similarity_embedded_umap_ibm = umap.UMAP(n_components=2).fit_transform(original_distance_matrix_ibm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Run UMAP on data\n",
    "\n",
    "three_similarity_embedded_umap_levenshtein = umap.UMAP(n_components=3).fit_transform(original_distance_matrix_levenshtein)\n",
    "three_similarity_embedded_umap_jaro = umap.UMAP(n_components=3).fit_transform(original_distance_matrix_jaro)\n",
    "three_similarity_embedded_umap_ibm = umap.UMAP(n_components=3).fit_transform(original_distance_matrix_ibm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprare 3D Data for plots\n",
    "\n",
    "three_umap_levenshtein = pandas.DataFrame()\n",
    "three_umap_levenshtein['umap-x'] = three_similarity_embedded_umap_levenshtein[:,0]\n",
    "three_umap_levenshtein['umap-y'] = three_similarity_embedded_umap_levenshtein[:,1]\n",
    "three_umap_levenshtein['umap-z'] = three_similarity_embedded_umap_levenshtein[:,2]\n",
    "three_umap_levenshtein['token'] = original_distance_matrix_levenshtein.index\n",
    "\n",
    "three_umap_jaro = pandas.DataFrame()\n",
    "three_umap_jaro['umap-x'] = three_similarity_embedded_umap_jaro[:,0]\n",
    "three_umap_jaro['umap-y'] = three_similarity_embedded_umap_jaro[:,1]\n",
    "three_umap_jaro['umap-z'] = three_similarity_embedded_umap_jaro[:,2]\n",
    "three_umap_jaro['token'] = original_distance_matrix_jaro.index\n",
    "\n",
    "three_umap_ibm = pandas.DataFrame()\n",
    "three_umap_ibm['umap-x'] = three_similarity_embedded_umap_ibm[:,0]\n",
    "three_umap_ibm['umap-y'] = three_similarity_embedded_umap_ibm[:,1]\n",
    "three_umap_ibm['umap-z'] = three_similarity_embedded_umap_ibm[:,2]\n",
    "three_umap_ibm['token'] = original_distance_matrix_ibm.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprare 2D Data for plots\n",
    "\n",
    "two_umap_levenshtein = pandas.DataFrame()\n",
    "two_umap_levenshtein['umap-x'] = two_similarity_embedded_umap_levenshtein[:,0]\n",
    "two_umap_levenshtein['umap-y'] = two_similarity_embedded_umap_levenshtein[:,1]\n",
    "two_umap_levenshtein['token'] = original_distance_matrix_levenshtein.index\n",
    "\n",
    "two_umap_jaro = pandas.DataFrame()\n",
    "two_umap_jaro['umap-x'] = two_similarity_embedded_umap_jaro[:,0]\n",
    "two_umap_jaro['umap-y'] = two_similarity_embedded_umap_jaro[:,1]\n",
    "two_umap_jaro['token'] = original_distance_matrix_jaro.index\n",
    "\n",
    "two_umap_ibm = pandas.DataFrame()\n",
    "two_umap_ibm['umap-x'] = two_similarity_embedded_umap_ibm[:,0]\n",
    "two_umap_ibm['umap-y'] = two_similarity_embedded_umap_ibm[:,1]\n",
    "two_umap_ibm['token'] = original_distance_matrix_ibm.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Levenshtein-UMAP 3D Scatterplot\n",
    "\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=three_umap_levenshtein['umap-x'],\n",
    "    y=three_umap_levenshtein['umap-y'],\n",
    "    z=three_umap_levenshtein['umap-z'],\n",
    "    mode='markers',\n",
    "    text=three_umap_levenshtein['token'],\n",
    "    marker=dict(\n",
    "        size=2,\n",
    "        color='steelblue',\n",
    "        opacity=1\n",
    "    )\n",
    ")])\n",
    "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jaro-UMAP 3D Scatterplot\n",
    "\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=three_umap_jaro['umap-x'],\n",
    "    y=three_umap_jaro['umap-y'],\n",
    "    z=three_umap_jaro['umap-z'],\n",
    "    mode='markers',\n",
    "    text=three_umap_jaro['token'],\n",
    "    marker=dict(\n",
    "        size=2,\n",
    "        color='salmon',\n",
    "        opacity=1\n",
    "    )\n",
    ")])\n",
    "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IBM-UMAP 3D Scatterplot\n",
    "\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=three_umap_ibm['umap-x'],\n",
    "    y=three_umap_ibm['umap-y'],\n",
    "    z=three_umap_ibm['umap-z'],\n",
    "    mode='markers',\n",
    "    text=three_umap_ibm['token'],\n",
    "    marker=dict(\n",
    "        size=2,\n",
    "        color='seagreen',\n",
    "        opacity=1\n",
    "    )\n",
    ")])\n",
    "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Levenshtein-UMAP 2D Scatterplot\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "sns.scatterplot(\n",
    "    x='umap-x',\n",
    "    y='umap-y',\n",
    "    data=two_umap_levenshtein,\n",
    "    color='steelblue',\n",
    "    alpha=0.5\n",
    ").set(title=CORPUS_NAME + '-levenshtein-umap', xlabel=None, ylabel=None)\n",
    "\n",
    "plt.savefig(CORPUS_NAME + '-levenshtein-umap.png', \n",
    "            facecolor='white',\n",
    "            bbox_inches='tight', \n",
    "            dpi=100,\n",
    "            pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jaro-UMAP 2D Scatterplot\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "sns.scatterplot(\n",
    "    x='umap-x',\n",
    "    y='umap-y',\n",
    "    data=two_umap_jaro,\n",
    "    color='salmon',\n",
    "    alpha=0.5\n",
    ").set(title=CORPUS_NAME + '-jaro-umap', xlabel=None, ylabel=None)\n",
    "\n",
    "plt.savefig(CORPUS_NAME + '-jaro-umap.png', \n",
    "            facecolor='white',\n",
    "            bbox_inches='tight', \n",
    "            dpi=100,\n",
    "            pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IBM-UMAP 2D Scatterplot\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "sns.scatterplot(\n",
    "    x='umap-x',\n",
    "    y='umap-y',\n",
    "    data=two_umap_ibm,\n",
    "    color='seagreen',\n",
    "    alpha=0.5\n",
    ").set(title=CORPUS_NAME + '-ibm-umap', xlabel=None, ylabel=None)\n",
    "\n",
    "plt.savefig(CORPUS_NAME + '-ibm-umap.png', \n",
    "            facecolor='white',\n",
    "            bbox_inches='tight', \n",
    "            dpi=100,\n",
    "            pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# t-SNE\n",
    "\n",
    "two_similarity_embedded_tsne_levenshtein = sklearn.manifold.TSNE(n_components=2).fit_transform(original_distance_matrix_levenshtein)\n",
    "two_similarity_embedded_tsne_jaro = sklearn.manifold.TSNE(n_components=2).fit_transform(original_distance_matrix_jaro)\n",
    "two_similarity_embedded_tsne_ibm = sklearn.manifold.TSNE(n_components=2).fit_transform(original_distance_matrix_ibm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# t-SNE\n",
    "\n",
    "three_similarity_embedded_tsne_levenshtein = sklearn.manifold.TSNE(n_components=3).fit_transform(original_distance_matrix_levenshtein)\n",
    "three_similarity_embedded_tsne_jaro = sklearn.manifold.TSNE(n_components=3).fit_transform(original_distance_matrix_jaro)\n",
    "three_similarity_embedded_tsne_ibm = sklearn.manifold.TSNE(n_components=3).fit_transform(original_distance_matrix_ibm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprare 3D Data for plots\n",
    "\n",
    "three_tsne_levenshtein = pandas.DataFrame()\n",
    "three_tsne_levenshtein['tsne-x'] = three_similarity_embedded_tsne_levenshtein[:,0]\n",
    "three_tsne_levenshtein['tsne-y'] = three_similarity_embedded_tsne_levenshtein[:,1]\n",
    "three_tsne_levenshtein['tsne-z'] = three_similarity_embedded_tsne_levenshtein[:,2]\n",
    "three_tsne_levenshtein['token'] = original_distance_matrix_levenshtein.index\n",
    "\n",
    "three_tsne_jaro = pandas.DataFrame()\n",
    "three_tsne_jaro['tsne-x'] = three_similarity_embedded_tsne_jaro[:,0]\n",
    "three_tsne_jaro['tsne-y'] = three_similarity_embedded_tsne_jaro[:,1]\n",
    "three_tsne_jaro['tsne-z'] = three_similarity_embedded_tsne_jaro[:,2]\n",
    "three_tsne_jaro['token'] = original_distance_matrix_jaro.index\n",
    "\n",
    "three_tsne_ibm = pandas.DataFrame()\n",
    "three_tsne_ibm['tsne-x'] = three_similarity_embedded_tsne_ibm[:,0]\n",
    "three_tsne_ibm['tsne-y'] = three_similarity_embedded_tsne_ibm[:,1]\n",
    "three_tsne_ibm['tsne-z'] = three_similarity_embedded_tsne_ibm[:,2]\n",
    "three_tsne_ibm['token'] = original_distance_matrix_ibm.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Preprare 2D Data for plots\n",
    "\n",
    "two_tsne_levenshtein = pandas.DataFrame()\n",
    "two_tsne_levenshtein['tsne-x'] = two_similarity_embedded_tsne_levenshtein[:,0]\n",
    "two_tsne_levenshtein['tsne-y'] = two_similarity_embedded_tsne_levenshtein[:,1]\n",
    "two_tsne_levenshtein['token'] = original_distance_matrix_levenshtein.index\n",
    "\n",
    "two_tsne_jaro = pandas.DataFrame()\n",
    "two_tsne_jaro['tsne-x'] = two_similarity_embedded_tsne_jaro[:,0]\n",
    "two_tsne_jaro['tsne-y'] = two_similarity_embedded_tsne_jaro[:,1]\n",
    "two_tsne_jaro['token'] = original_distance_matrix_jaro.index\n",
    "\n",
    "two_tsne_ibm = pandas.DataFrame()\n",
    "two_tsne_ibm['tsne-x'] = two_similarity_embedded_tsne_ibm[:,0]\n",
    "two_tsne_ibm['tsne-y'] = two_similarity_embedded_tsne_ibm[:,1]\n",
    "two_tsne_ibm['token'] = original_distance_matrix_ibm.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Levenshtein-TSNE 3D Scatterplot\n",
    "\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=three_tsne_levenshtein['tsne-x'],\n",
    "    y=three_tsne_levenshtein['tsne-y'],\n",
    "    z=three_tsne_levenshtein['tsne-z'],\n",
    "    mode='markers',\n",
    "    text=three_tsne_levenshtein['token'],\n",
    "    marker=dict(\n",
    "        size=2,\n",
    "        color='steelblue',\n",
    "        opacity=1\n",
    "    )\n",
    ")])\n",
    "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jaro-TSNE 3D Scatterplot\n",
    "\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=three_tsne_jaro['tsne-x'],\n",
    "    y=three_tsne_jaro['tsne-y'],\n",
    "    z=three_tsne_jaro['tsne-z'],\n",
    "    mode='markers',\n",
    "    text=three_tsne_jaro['token'],\n",
    "    marker=dict(\n",
    "        size=2,\n",
    "        color='salmon',\n",
    "        opacity=1\n",
    "    )\n",
    ")])\n",
    "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IBM-TSNE 3D Scatterplot\n",
    "\n",
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=three_tsne_ibm['tsne-x'],\n",
    "    y=three_tsne_ibm['tsne-y'],\n",
    "    z=three_tsne_ibm['tsne-z'],\n",
    "    mode='markers',\n",
    "    text=three_tsne_ibm['token'],\n",
    "    marker=dict(\n",
    "        size=2,\n",
    "        color='seagreen',\n",
    "        opacity=1\n",
    "    )\n",
    ")])\n",
    "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Levenshtein-TSNE 2D Scatterplot\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "sns.scatterplot(\n",
    "    x='tsne-x',\n",
    "    y='tsne-y',\n",
    "    data=two_tsne_levenshtein,\n",
    "    color='steelblue',\n",
    "    alpha=0.5\n",
    ").set(title=CORPUS_NAME + '-levenshtein-tsne', xlabel=None, ylabel=None)\n",
    "\n",
    "plt.savefig(CORPUS_NAME + '-levenshtein-tsne.png', \n",
    "            facecolor='white',\n",
    "            bbox_inches='tight', \n",
    "            dpi=100,\n",
    "            pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jaro-TSNE 2D Scatterplot\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "sns.scatterplot(\n",
    "    x='tsne-x',\n",
    "    y='tsne-y',\n",
    "    data=two_tsne_jaro,\n",
    "    color='salmon',\n",
    "    alpha=0.5\n",
    ").set(title=CORPUS_NAME + '-jaro-tsne', xlabel=None, ylabel=None)\n",
    "\n",
    "plt.savefig(CORPUS_NAME + '-jaro-tsne.png', \n",
    "            facecolor='white',\n",
    "            bbox_inches='tight', \n",
    "            dpi=100,\n",
    "            pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IBM-TSNE 2D Scatterplot\n",
    "\n",
    "plt.figure(figsize=(20,20))\n",
    "sns.scatterplot(\n",
    "    x='tsne-x',\n",
    "    y='tsne-y',\n",
    "    data=two_tsne_ibm,\n",
    "    color='seagreen',\n",
    "    alpha=0.5\n",
    ").set(title=CORPUS_NAME + '-ibm-tsne', xlabel=None, ylabel=None)\n",
    "\n",
    "plt.savefig(CORPUS_NAME + '-ibm-tsne.png', \n",
    "            facecolor='white',\n",
    "            bbox_inches='tight', \n",
    "            dpi=100,\n",
    "            pad_inches=0.1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
