{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn.manifold\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import umap\n",
    "import pandas\n",
    "import pickle\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT = '../../histnorm/datasets/historical/spanish/spanish-ps<n>.test.txt'\n",
    "ENCODING = 'utf-8'\n",
    "CORPUS_NAME = 'spanish-ps'\n",
    "\n",
    "tokens = []\n",
    "\n",
    "# Loading input file, which has the original and modernised token in each line separated by a \\t\n",
    "for n in range(16,20):\n",
    "    inputfile = INPUT.replace('<n>', str(n))\n",
    "    with open(inputfile, 'r', encoding=ENCODING) as infile:\n",
    "        tokens += [line.strip().split('\\t') for line in infile]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the original and modernised tokens and types\n",
    "tokens_original = [token[0] for token in tokens if len(token) > 1]\n",
    "tokens_modernised = [token[1] for token in tokens if len(token) > 1]\n",
    "\n",
    "types_original = list(set(tokens_original))\n",
    "types_modernised = list(set(tokens_modernised))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ttr(types, tokens):\n",
    "    \"\"\"\n",
    "    Calculating Type-Token Ration\n",
    "    \"\"\"\n",
    "    return len(types)/len(tokens)\n",
    "\n",
    "assert ttr([0]*5, [0]*10)  == 0.5\n",
    "assert ttr([0]*10, [0]*10) == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(CORPUS_NAME)\n",
    "print('Tokens Original Example: {}'.format(tokens_original[:10]))\n",
    "print('Tokens Original Count: {}'.format(len(tokens_original)))\n",
    "print('Types Original Example: {}'.format(types_original[:10]))\n",
    "print('Types Original Count: {}'.format(len(types_original)))\n",
    "print('Type/Token Ratio Original: {:2.2%}'.format(ttr(types_original, tokens_original)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(CORPUS_NAME)\n",
    "print('Tokens Modernised Example: {}'.format(tokens_modernised[:10]))\n",
    "print('Tokens Modernised Count: {}'.format(len(tokens_modernised)))\n",
    "print('Types Modernised Example: {}'.format(types_modernised[:10]))\n",
    "print('Types Modernised Count: {}'.format(len(types_modernised)))\n",
    "print('Type/Token Modernised Original: {:2.2%}'.format(ttr(types_modernised, tokens_modernised)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def levenshtein(string1, string2):\n",
    "    \"\"\"\n",
    "    Levenshtein Distance between two strings\n",
    "    \"\"\"\n",
    "    if string1 == string2:\n",
    "        return 0\n",
    "\n",
    "    rows = len(string1) + 1\n",
    "    cols = len(string2) + 1\n",
    "    dist = [[0 for c in range(cols)] for r in range(rows)]\n",
    "\n",
    "    for j in range(1, rows):\n",
    "        dist[j][0] = j\n",
    "    for i in range(1, cols):\n",
    "        dist[0][i] = i\n",
    "\n",
    "    for col in range(1, cols):\n",
    "        for row in range(1, rows):\n",
    "            cost = 1\n",
    "            if string1[row - 1] == string2[col - 1]:\n",
    "                cost = 0\n",
    "            dist[row][col] = min(dist[row - 1][col] + 1, dist[row][col - 1] + 1, dist[row - 1][col - 1] + cost)\n",
    "\n",
    "    return dist[row][col]\n",
    "\n",
    "assert levenshtein('foobar', 'foobar') == 0\n",
    "assert levenshtein('foobar', 'foubar') == 1\n",
    "assert levenshtein('foobar', 'fuubar') == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "similarity = levenshtein\n",
    "cache_name = CORPUS_NAME + '-pairwise-distance.pickle'\n",
    "\n",
    "if os.path.exists(cache_name):\n",
    "    print('> Using Cache')\n",
    "    # Unpacking pickled Pairwise Distances\n",
    "    with open(cache_name, 'rb' ) as pickler:    \n",
    "        cache = pickle.load(pickler)\n",
    "        types_original_pairwise_distance = cache['types_original_pairwise_distance']\n",
    "        types_modernised_pairwise_distance = cache['types_modernised_pairwise_distance']\n",
    "\n",
    "else:\n",
    "    # Calculating string distances for each type\n",
    "    types_original_reshaped = np.array(types_original).reshape(-1,1)\n",
    "    types_original_pairwise_distance = scipy.spatial.distance.pdist(types_original_reshaped, lambda x,y: similarity(str(x[0]),str(y[0])))   \n",
    "\n",
    "    types_modernised_reshaped = np.array(types_modernised).reshape(-1,1)\n",
    "    types_modernised_pairwise_distance = scipy.spatial.distance.pdist(types_modernised_reshaped, lambda x,y: similarity(str(x[0]),str(y[0])))   \n",
    "\n",
    "    print('> Writing Cache')\n",
    "    with open(cache_name, 'wb' ) as pickler:\n",
    "        data = {\n",
    "            'types_original_pairwise_distance': types_original_pairwise_distance,\n",
    "            'types_modernised_pairwise_distance': types_modernised_pairwise_distance\n",
    "        }\n",
    "        pickle.dump(data, pickler) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Transforming pairwise distances into a full similarity matrix\n",
    "original_distance_matrix = pandas.DataFrame(scipy.spatial.distance.squareform(types_original_pairwise_distance), index=types_original, columns=types_original)\n",
    "modernised_distance_matrix = pandas.DataFrame(scipy.spatial.distance.squareform(types_modernised_pairwise_distance), index=types_modernised, columns=types_modernised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Running t-SNE on similarity matrix\n",
    "\n",
    "cache_name = CORPUS_NAME + '-tsne.pickle'\n",
    "\n",
    "if os.path.exists(cache_name):\n",
    "    print('> Using Cache')\n",
    "    # Unpacking pickled Pairwise Distances\n",
    "    with open(cache_name, 'rb' ) as pickler:    \n",
    "        cache = pickle.load(pickler)\n",
    "        original_similarity_embedded = cache['original_similarity_embedded']\n",
    "        modernised_similarity_embedded = cache['modernised_similarity_embedded']\n",
    "\n",
    "else:\n",
    "    original_similarity_embedded = sklearn.manifold.TSNE(n_components=2).fit_transform(original_distance_matrix)\n",
    "    modernised_similarity_embedded = sklearn.manifold.TSNE(n_components=2).fit_transform(modernised_distance_matrix)\n",
    "    \n",
    "    print('> Writing Cache')\n",
    "    with open(cache_name, 'wb' ) as pickler:\n",
    "        data = {\n",
    "            'original_similarity_embedded': original_similarity_embedded,\n",
    "            'modernised_similarity_embedded': modernised_similarity_embedded\n",
    "        }\n",
    "        pickle.dump(data, pickler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Running UMAP on similarity matrix\n",
    "\n",
    "cache_name = CORPUS_NAME + '-umap.pickle'\n",
    "\n",
    "if os.path.exists(cache_name):\n",
    "    print('> Using Cache')\n",
    "    # Unpacking pickled Pairwise Distances\n",
    "    with open(cache_name, 'rb' ) as pickler:    \n",
    "        cache = pickle.load(pickler)\n",
    "        original_similarity_embedded_umap = cache['original_similarity_embedded_umap']\n",
    "        modernised_similarity_embedded_umap = cache['modernised_similarity_embedded_umap']\n",
    "\n",
    "else:\n",
    "    original_similarity_embedded_umap = umap.UMAP(n_components=2).fit_transform(original_distance_matrix)\n",
    "    modernised_similarity_embedded_umap = umap.UMAP(n_components=2).fit_transform(modernised_distance_matrix)\n",
    "    \n",
    "    print('> Writing Cache')\n",
    "    with open(cache_name, 'wb' ) as pickler:\n",
    "        data = {\n",
    "            'original_similarity_embedded_umap': original_similarity_embedded_umap,\n",
    "            'modernised_similarity_embedded_umap': modernised_similarity_embedded_umap\n",
    "        }\n",
    "        pickle.dump(data, pickler)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_tsne = pandas.DataFrame()\n",
    "original_tsne['tsne-x-original'] = original_similarity_embedded[:,0]\n",
    "original_tsne['tsne-y-original'] = original_similarity_embedded[:,1]\n",
    "\n",
    "modernised_tsne = pandas.DataFrame()\n",
    "modernised_tsne['tsne-x-modernised'] = modernised_similarity_embedded[:,0]\n",
    "modernised_tsne['tsne-y-modernised'] = modernised_similarity_embedded[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_umap = pandas.DataFrame()\n",
    "original_umap['umap-x-original'] = original_similarity_embedded_umap[:,0]\n",
    "original_umap['umap-y-original'] = original_similarity_embedded_umap[:,1]\n",
    "\n",
    "modernised_umap = pandas.DataFrame()\n",
    "modernised_umap['umap-x-modernised'] = modernised_similarity_embedded_umap[:,0]\n",
    "modernised_umap['umap-y-modernised'] = modernised_similarity_embedded_umap[:,1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "sns.scatterplot(\n",
    "    x='tsne-x-original', y='tsne-y-original',\n",
    "    data=original_tsne,\n",
    "    alpha=0.5\n",
    ").set_title(CORPUS_NAME + '-tsne-original')\n",
    "\n",
    "plt.savefig('spanish-ps-tsne-original.png', \n",
    "            facecolor='white',\n",
    "            bbox_inches='tight', \n",
    "            dpi=100,\n",
    "            pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "sns.scatterplot(\n",
    "    x='tsne-x-modernised', y='tsne-y-modernised',\n",
    "    data=modernised_tsne,\n",
    "    alpha=0.5\n",
    ").set_title(CORPUS_NAME + '-tsne-modernised')\n",
    "\n",
    "plt.savefig(CORPUS_NAME + '-tsne-modernised.png', \n",
    "            facecolor='white',\n",
    "            bbox_inches='tight', \n",
    "            dpi=100,\n",
    "            pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "sns.scatterplot(\n",
    "    x='umap-x-original', y='umap-y-original',\n",
    "    data=original_umap,\n",
    "    alpha=0.5\n",
    ").set_title(CORPUS_NAME + '-umap-original')\n",
    "\n",
    "plt.savefig(CORPUS_NAME + '-umap-original.png', \n",
    "            facecolor='white',\n",
    "            bbox_inches='tight', \n",
    "            dpi=100,\n",
    "            pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(20,20))\n",
    "sns.scatterplot(\n",
    "    x='umap-x-modernised', y='umap-y-modernised',\n",
    "    data=modernised_umap,\n",
    "    alpha=0.5\n",
    ").set_title(CORPUS_NAME + '-umap-modernised')\n",
    "\n",
    "plt.savefig(CORPUS_NAME + '-umap-modernised.png', \n",
    "            facecolor='white',\n",
    "            bbox_inches='tight', \n",
    "            dpi=100,\n",
    "            pad_inches=0.1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "# Clustering the pairwise distances\n",
    "linkage_method = 'ward'\n",
    "original_clustering = scipy.cluster.hierarchy.linkage(types_original_pairwise_distance, linkage_method)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import reduce\n",
    "from json import dump\n",
    "\n",
    "labels = dict(enumerate(types_original))\n",
    "\n",
    "def add_nodes(node, parent):\n",
    "    \"\"\"\n",
    "    Recursively build tree as dict\n",
    "    \"\"\"\n",
    "    new_node = dict(node_id=node.id, children=[], distance=node.dist)\n",
    "    parent['children'].append(new_node)\n",
    "    if node.left: add_nodes(node.left, new_node)\n",
    "    if node.right: add_nodes(node.right, new_node)\n",
    "\n",
    "def add_labels(node):\n",
    "    \"\"\"\n",
    "    Recursively add labels to the tree\n",
    "    \"\"\"\n",
    "    is_leaf = len(node['children']) == 0\n",
    "\n",
    "    if is_leaf: \n",
    "        node['name'] = labels[node['node_id']]\n",
    "    else:\n",
    "        list(map(add_labels, node['children']))  \n",
    "    del node['node_id']\n",
    "\n",
    "if not os.path.exists(CORPUS_NAME + '-cluster-original.json'):\n",
    "    # Transforming Cluster into JSON Tree\n",
    "    scipy_tree = scipy.cluster.hierarchy.to_tree(original_clustering, rd=False)\n",
    "    tree = dict(name='root', children=[], distance=scipy_tree.dist)\n",
    "    \n",
    "    add_nodes(scipy_tree, tree)\n",
    "    add_labels(tree['children'][0])\n",
    "    \n",
    "    with open(CORPUS_NAME + '-cluster-original.json', 'w') as clustering:\n",
    "        dump(tree, clustering, indent=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
