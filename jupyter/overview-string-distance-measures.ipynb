{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# String Distance Measures\n",
    "\n",
    "Implementation of various String Distance Measures in Python. This list is not extensive.\n",
    "\n",
    "## Token-based\n",
    "- Longest Common Substring Distance\n",
    "- Jaccard Distance\n",
    "- Overlap Coefficient\n",
    "- Cosine\n",
    "\n",
    "## Edit-based\n",
    "- Hamming Distance\n",
    "- Levenshtein Distance\n",
    "- Needleman-Wunch Distance\n",
    "- Optimal Damerau-Levenshtein Distance\n",
    "- Jaro Distance\n",
    "- Jaro-Winkler Distance\n",
    "\n",
    "# Hybrid\n",
    "- IBM (LCS-Levenshtein Normalized)\n",
    "- Monge Elkan Distance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Longest Common Substring distance\n",
    "\n",
    "def longest_common_string(string1, string2):\n",
    "    if string1 == string2:\n",
    "        return len(string1)\n",
    "    \n",
    "    rows = len(string1) + 1\n",
    "    cols = len(string2) + 1\n",
    "    table = [[0 for c in range(cols)] for r in range(rows)]\n",
    "\n",
    "    longest = 0\n",
    "    for col in range(cols):\n",
    "        for row in range(rows):\n",
    "            if col == 0 and row == 0:\n",
    "                table[row][col] = 0\n",
    "            if string1[row - 1] == string2[col - 1]:\n",
    "                table[row][col] = table[row - 1][col - 1] + 1\n",
    "                longest = max(longest, table[row][col])\n",
    "            else:\n",
    "                table[row][col] = 0\n",
    "    \n",
    "    return longest\n",
    "\n",
    "assert longest_common_string('', '') == 0\n",
    "assert longest_common_string('foobar', 'foobar') == 6\n",
    "assert longest_common_string('foobar', 'foo') == 3\n",
    "assert longest_common_string('foobar', 'f') == 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def ngrams(string, n=2):\n",
    "    # N-Gram helper function\n",
    "    return set([string[i:i + n] for i in range(0, len(string) - n + 1 )])\n",
    "\n",
    "# Jaccard Distance\n",
    "\n",
    "def jaccard(string1, string2):\n",
    "    if string1 == string2:\n",
    "        return 0.0\n",
    "    \n",
    "    ngrams1 = ngrams(string1)\n",
    "    ngrams2 = ngrams(string2)\n",
    "    \n",
    "    unions = len(list(ngrams1.union(ngrams2)))\n",
    "    qgrams = len(ngrams1.intersection(ngrams2))\n",
    "    \n",
    "    return 1 - qgrams / unions\n",
    "    \n",
    "assert jaccard('foobar', 'foobar') == 0.0\n",
    "assert jaccard('foobar', 'foo') == 0.6\n",
    "assert jaccard('foobar', 'xyz') == 1.0\n",
    "assert jaccard('', '') == 0.0\n",
    "\n",
    "# Overlap coefficient\n",
    "\n",
    "def overlap(string1, string2):\n",
    "    ngrams1 = ngrams(string1)\n",
    "    ngrams2 = ngrams(string2)\n",
    "    \n",
    "    qgrams = len(ngrams1.intersection(ngrams2))\n",
    "\n",
    "    return qgrams / len(min(ngrams1, ngrams2))\n",
    "\n",
    "assert overlap('foobar', 'foobar') == 1.0\n",
    "assert overlap('foo', 'foobar') == 1.0\n",
    "assert overlap('barfoo', 'foobar') == 0.8\n",
    "assert overlap('duane', 'dwayne') == 0.25\n",
    "\n",
    "# Dice\n",
    "\n",
    "def dice(string1, string2):\n",
    "    ngrams1 = ngrams(string1)\n",
    "    ngrams2 = ngrams(string2)\n",
    "    \n",
    "    qgrams = len(ngrams1.intersection(ngrams2))\n",
    "\n",
    "    return 2 * ( qgrams / (len(ngrams1) + len(ngrams2)))\n",
    "\n",
    "assert dice('foobar', 'foobar') == 1.0\n",
    "assert dice('foo', 'foobar') == 0.5714285714285714\n",
    "assert dice('barfoo', 'foobar') == 0.8\n",
    "assert dice('duane', 'dwayne') == 0.2222222222222222\n",
    "\n",
    "# Cosine\n",
    "\n",
    "from math import sqrt\n",
    "\n",
    "def cosine(string1, string2):\n",
    "    \n",
    "    if string1 == string2:\n",
    "        return 1.0\n",
    "    \n",
    "    ngrams1 = ngrams(string1)\n",
    "    ngrams2 = ngrams(string2)\n",
    "    \n",
    "    qgrams = len(ngrams1.intersection(ngrams2))\n",
    "\n",
    "    return qgrams / (sqrt(len(ngrams1)) * sqrt(len(ngrams2)))\n",
    "\n",
    "assert cosine('foobar', 'foobar') == 1.0\n",
    "assert cosine('foobar', 'foo') == 0.6324555320336759\n",
    "assert cosine('foobar', 'barfoo') == 0.7999999999999998"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hamming Distance\n",
    "# Hint: Only for strings of equal length\n",
    "\n",
    "def hamming(string1, string2):\n",
    "    assert len(string1) == len(string2)\n",
    "    return sum([char1 != char2 for char1, char2 in zip(string1, string2)])\n",
    "\n",
    "assert hamming('', '') == 0\n",
    "assert hamming('foobar', 'foobar') == 0\n",
    "assert hamming('foobar', 'foubar') == 1\n",
    "assert hamming('foobar', 'fuubar') == 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Levenshtein distance\n",
    "\n",
    "def levenshtein(string1, string2):\n",
    "\n",
    "    if string1 == string2:\n",
    "        return 0\n",
    "\n",
    "    rows = len(string1) + 1\n",
    "    cols = len(string2) + 1\n",
    "    dist = [[0 for c in range(cols)] for r in range(rows)]\n",
    "\n",
    "    for j in range(1, rows):\n",
    "        dist[j][0] = j\n",
    "    for i in range(1, cols):\n",
    "        dist[0][i] = i\n",
    "\n",
    "    for col in range(1, cols):\n",
    "        for row in range(1, rows):\n",
    "            cost = 1\n",
    "            if string1[row - 1] == string2[col - 1]:\n",
    "                cost = 0\n",
    "            dist[row][col] = min(dist[row - 1][col] + 1, dist[row][col - 1] + 1, dist[row - 1][col - 1] + cost)\n",
    "\n",
    "    # Enable for Debugging\n",
    "    # print('\\n'.join([''.join(['{:4}'.format(elem) for elem in row]) for row in dist]))\n",
    "    return dist[row][col]\n",
    "\n",
    "assert levenshtein('', '') == 0\n",
    "assert levenshtein('foobar', 'foobar') == 0\n",
    "assert levenshtein('foobar', 'foubar') == 1\n",
    "assert levenshtein('foobar', 'fuubar') == 2\n",
    "assert levenshtein('foobar', 'fuuar') == 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Needleman Wunsch distance\n",
    "\n",
    "def needleman_wunsch(string1, string2, gap_penalty=1):\n",
    "\n",
    "    if string1 == string2:\n",
    "        return len(string1)\n",
    "    \n",
    "    def match_score(char1, char2):\n",
    "        return 1 if char1 == char2 else 0\n",
    "\n",
    "    rows = len(string1) + 1\n",
    "    cols = len(string2) + 1\n",
    "    dist = [[0 for c in range(cols)] for r in range(rows)]\n",
    "\n",
    "    for j in range(1, rows):\n",
    "        dist[j][0] = -(j * gap_penalty)\n",
    "    for i in range(1, cols):\n",
    "        dist[0][i] = -(i * gap_penalty)\n",
    "    \n",
    "    for col in range(1, cols):\n",
    "        for row in range(1, rows):\n",
    "            match = dist[row - 1][col - 1] + match_score(string1[row - 1], string2[col - 1])\n",
    "            delete = dist[row - 1][col] - gap_penalty\n",
    "            insert = dist[row][col - 1] - gap_penalty\n",
    "            dist[row][col] = max(match, delete, insert)\n",
    "            \n",
    "    return dist[row][col]\n",
    "\n",
    "assert needleman_wunsch('', '') == 0\n",
    "assert needleman_wunsch('foobar', 'foobar') == 6\n",
    "assert needleman_wunsch('foobar', 'foo') == 0\n",
    "assert needleman_wunsch('foobar', 'fo bar') == 5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Optimal Damerau-Levenshtein distance\n",
    "\n",
    "def optimal_damerau_levenshtein(string1, string2):\n",
    "\n",
    "    if string1 == string2:\n",
    "        return 0\n",
    "    \n",
    "    rows = len(string1) + 1\n",
    "    cols = len(string2) + 1\n",
    "    dist = [[0 for c in range(cols)] for r in range(rows)]\n",
    "\n",
    "    for j in range(1, rows):\n",
    "        dist[j][0] = j\n",
    "    for i in range(1, cols):\n",
    "        dist[0][i] = i\n",
    "\n",
    "    for col in range(1, cols):\n",
    "        for row in range(1, rows):    \n",
    "            cost = 1\n",
    "            if string1[row - 1] == string2[col - 1]:\n",
    "                cost = 0\n",
    "            dist[row][col] = min(dist[row - 1][col] + 1, dist[row][col - 1] + 1, dist[row - 1][col - 1] + cost)\n",
    "            \n",
    "            if col > 1 and row > 1 and string1[row - 1] == string2[col - 2] and string1[row - 2] == string2[col - 1]:\n",
    "                dist[row][col] = min(dist[row][col], dist[row - 2][col - 2] + cost)\n",
    "            \n",
    "    return dist[row][col]\n",
    "\n",
    "assert optimal_damerau_levenshtein('', '') == 0\n",
    "assert optimal_damerau_levenshtein('foobar', 'foobar') == 0\n",
    "assert optimal_damerau_levenshtein('foobar', 'foubar') == 1\n",
    "assert optimal_damerau_levenshtein('foobar', 'fuubar') == 2\n",
    "assert optimal_damerau_levenshtein('foobar', 'fuuar') == 3\n",
    "assert optimal_damerau_levenshtein('foobar', 'oofbraa') == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jaro distance\n",
    "\n",
    "def jaro(string1, string2):\n",
    "\n",
    "    length1 = len(string1)\n",
    "    length2 = len(string2)\n",
    "   \n",
    "    if length1 == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    if string1 == string2:\n",
    "        return 1.0   \n",
    "\n",
    "    match_bound = max(length1, length2) // 2 - 1\n",
    "\n",
    "    matches = 0  \n",
    "    transpositions = 0\n",
    "\n",
    "    flagged_1 = [] \n",
    "    flagged_2 = []\n",
    "\n",
    "    for i in range(length1):\n",
    "        upperbound = min(i + match_bound, length2 - 1)\n",
    "        lowerbound = max(0, i - match_bound)\n",
    "        for j in range(lowerbound, upperbound + 1):\n",
    "            if string1[i] == string2[j] and j not in flagged_2:\n",
    "                matches += 1\n",
    "                flagged_1.append(i)\n",
    "                flagged_2.append(j)\n",
    "                break\n",
    "\n",
    "    flagged_2.sort()\n",
    "\n",
    "    for i, j in zip(flagged_1, flagged_2):\n",
    "        if string1[i] != string2[j]:\n",
    "            transpositions += 1\n",
    "\n",
    "    if matches == 0:\n",
    "        return 0.0\n",
    "\n",
    "    return (1/3 * ( matches / length1 + matches / length2 + (matches - transpositions // 2) / matches))\n",
    "\n",
    "assert jaro('foobar', 'foobar') == 1.0\n",
    "assert jaro('foobar', 'barfoo') == 0.4444444444444444\n",
    "assert jaro('duane', 'dwayne') == 0.8222222222222222\n",
    "assert jaro('hans', 'gruber') == 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# TODO Jaro-Winkler distance\n",
    "\n",
    "def jaro_winkler(string1, string2):\n",
    "     if string1 == string2:\n",
    "        return 1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IBM (LCS-Levenshtein Normalized)\n",
    "# Contractor, D., Faruquie, T. A., & Subramaniam, L. V. (2010, August). \n",
    "\n",
    "from itertools import groupby\n",
    "\n",
    "def lcs_ratio(string1, string2):\n",
    "    ratio = longest_common_string(string1, string2) / len(string1)\n",
    "    return ratio\n",
    "\n",
    "assert lcs_ratio('foobar', 'foobar') == 1.0\n",
    "assert lcs_ratio('foo', 'bar') == 0.0\n",
    "assert lcs_ratio('word', 'deoxyribonucleic') == 0.25\n",
    "\n",
    "\n",
    "def consonant_skeleton(string, vowels='aeiouy'):\n",
    "    without_vowels = ''.join([char for char in string if char not in vowels])     \n",
    "    deduplicated_consonants = ''.join(char for char, _ in groupby(without_vowels))\n",
    "    return deduplicated_consonants\n",
    "\n",
    "assert consonant_skeleton('foobar') == 'fbr'\n",
    "assert consonant_skeleton('ffoobbar') == 'fbr'\n",
    "assert consonant_skeleton('barfoobar') == 'brfbr'\n",
    "\n",
    "\n",
    "def ibm_similarity(string1, string2):\n",
    "    similarity = lcs_ratio(string1, string2) / (levenshtein (consonant_skeleton(string1), consonant_skeleton(string2)) + 1)\n",
    "    return similarity\n",
    "\n",
    "assert ibm_similarity('foobar', 'foobar') == 1.0\n",
    "assert ibm_similarity('foo', 'bar') == 0.0\n",
    "assert ibm_similarity('word', 'deoxyribonucleic') == 0.03125"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Monge-Elkan\n",
    "\n",
    "def ngrams(string, n=2):\n",
    "    # N-Gram helper function\n",
    "    return set([string[i:i + n] for i in range(0, len(string) - n + 1 )])\n",
    "\n",
    "def monge_elkan(string1, string2, similarity_function=levenshtein):\n",
    "    if string1 == string2:\n",
    "        return 1.0\n",
    "\n",
    "    ngrams1 = ngrams(string1)\n",
    "    ngrams2 = ngrams(string2)\n",
    "\n",
    "    sum_of_maxes = 0\n",
    "    for ngram1 in ngrams1:\n",
    "        max_sim = float('-inf')\n",
    "        for ngram2 in ngrams2:\n",
    "             max_sim = max(max_sim, similarity_function(ngram1, ngram2))\n",
    "        sum_of_maxes += max_sim\n",
    "        \n",
    "    return sum_of_maxes / len(ngrams1)\n",
    "\n",
    "monge_elkan('foo', 'bar')\n",
    "monge_elkan('foo', 'ksdfjsldk', similarity_function=optimal_damerau_levenshtein)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
