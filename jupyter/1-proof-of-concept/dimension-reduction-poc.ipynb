{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import scipy\n",
    "import sklearn.manifold\n",
    "import sklearn.decomposition\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "import plotly.graph_objects as go\n",
    "import umap\n",
    "import pandas\n",
    "import pickle\n",
    "import os\n",
    "import collections"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT = '../../histnorm/datasets/historical/german/german-anselm.test.txt'\n",
    "ENCODING = 'utf-8'\n",
    "CORPUS_NAME = 'german-anselm'\n",
    "\n",
    "# Loading input file, which has the original and modernised token in each line separated by a \\t\n",
    "with open(INPUT, 'r', encoding=ENCODING) as infile:\n",
    "    tokens = [line.strip().split('\\t') for line in infile]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the original and modernised tokens and types\n",
    "tokens_original = [token[0] for token in tokens[:5000]]\n",
    "tokens_modernised = [token[1] for token in tokens[:5000]]\n",
    "types_original = list(set(tokens_original))\n",
    "types_modernised = list(set(tokens_modernised))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Levenshtein Distance\n",
    "def levenshtein(string1, string2):\n",
    "    if string1 == string2:\n",
    "        return 0\n",
    "\n",
    "    if not string2:\n",
    "        return len(string1)\n",
    "    if not string1:\n",
    "        return len(string2)\n",
    "\n",
    "    rows = len(string1) + 1\n",
    "    cols = len(string2) + 1\n",
    "    dist = [[0 for c in range(cols)] for r in range(rows)]\n",
    "\n",
    "    for j in range(1, rows):\n",
    "        dist[j][0] = j\n",
    "    for i in range(1, cols):\n",
    "        dist[0][i] = i\n",
    "\n",
    "    for col in range(1, cols):\n",
    "        for row in range(1, rows):\n",
    "            cost = 1\n",
    "            if string1[row - 1] == string2[col - 1]:\n",
    "                cost = 0\n",
    "            dist[row][col] = min(dist[row - 1][col] + 1, dist[row][col - 1] + 1, dist[row - 1][col - 1] + cost)\n",
    "\n",
    "    # Enable for Debugging\n",
    "    # print('\\n'.join([''.join(['{:4}'.format(elem) for elem in row]) for row in dist]))\n",
    "    return dist[row][col]\n",
    "\n",
    "assert levenshtein('', '') == 0\n",
    "assert levenshtein('foobar', 'foobar') == 0\n",
    "assert levenshtein('foobar', 'foubar') == 1\n",
    "assert levenshtein('foobar', 'fuubar') == 2\n",
    "assert levenshtein('foobar', 'fuuar') == 3\n",
    "assert levenshtein('foobar', '') == 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Jaro Similarily\n",
    "def jaro(string1, string2):\n",
    "\n",
    "    length1 = len(string1)\n",
    "    length2 = len(string2)\n",
    "   \n",
    "    if length1 == 0:\n",
    "        return 0.0\n",
    "    \n",
    "    if string1 == string2:\n",
    "        return 1.0   \n",
    "\n",
    "    match_bound = max(length1, length2) // 2 - 1\n",
    "\n",
    "    matches = 0  \n",
    "    transpositions = 0\n",
    "\n",
    "    flagged_1 = [] \n",
    "    flagged_2 = []\n",
    "\n",
    "    for i in range(length1):\n",
    "        upperbound = min(i + match_bound, length2 - 1)\n",
    "        lowerbound = max(0, i - match_bound)\n",
    "        for j in range(lowerbound, upperbound + 1):\n",
    "            if string1[i] == string2[j] and j not in flagged_2:\n",
    "                matches += 1\n",
    "                flagged_1.append(i)\n",
    "                flagged_2.append(j)\n",
    "                break\n",
    "\n",
    "    flagged_2.sort()\n",
    "\n",
    "    for i, j in zip(flagged_1, flagged_2):\n",
    "        if string1[i] != string2[j]:\n",
    "            transpositions += 1\n",
    "\n",
    "    if matches == 0:\n",
    "        return 0.0\n",
    "\n",
    "    return (1/3 * ( matches / length1 + matches / length2 + (matches - transpositions // 2) / matches))\n",
    "\n",
    "assert jaro('', '') == 0.0\n",
    "assert jaro('foobar', '') == 0.0\n",
    "assert jaro('foobar', 'foobar') == 1.0\n",
    "assert jaro('foobar', 'barfoo') == 0.4444444444444444\n",
    "assert jaro('duane', 'dwayne') == 0.8222222222222222\n",
    "assert jaro('hans', 'gruber') == 0.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IBM (LCS-Levenshtein Normalized)\n",
    "\n",
    "# Contractor, D., Faruquie, T. A., & Subramaniam, L. V. (2010, August). \n",
    "# Unsupervised cleansing of noisy text. \n",
    "# In Proceedings of the 23rd International Conference on Computational Linguistics:\n",
    "# Posters (pp. 189-196). Association for Computational Linguistics.\n",
    "\n",
    "from itertools import groupby\n",
    "\n",
    "# Longest Common Substring\n",
    "def longest_common_string(string1, string2):\n",
    "    if string1 == string2:\n",
    "        return len(string1)\n",
    "\n",
    "    if not string1 or not string2:\n",
    "        return 0\n",
    "    \n",
    "    rows = len(string1) + 1\n",
    "    cols = len(string2) + 1\n",
    "    table = [[0 for c in range(cols)] for r in range(rows)]\n",
    "\n",
    "    longest = 0\n",
    "    for col in range(cols):\n",
    "        for row in range(rows):\n",
    "            if col == 0 and row == 0:\n",
    "                table[row][col] = 0\n",
    "            if string1[row - 1] == string2[col - 1]:\n",
    "                table[row][col] = table[row - 1][col - 1] + 1\n",
    "                longest = max(longest, table[row][col])\n",
    "            else:\n",
    "                table[row][col] = 0\n",
    "    \n",
    "    return longest\n",
    "\n",
    "assert longest_common_string('', '') == 0\n",
    "assert longest_common_string('foobar', '') == 0\n",
    "assert longest_common_string('foobar', 'foobar') == 6\n",
    "assert longest_common_string('foobar', 'foo') == 3\n",
    "assert longest_common_string('foobar', 'f') == 1\n",
    "\n",
    "\n",
    "def lcs_ratio(string1, string2):\n",
    "    if not string1 or not string2:\n",
    "        return 0.0\n",
    "    ratio = longest_common_string(string1, string2) / len(string1)\n",
    "    return ratio\n",
    "\n",
    "assert lcs_ratio('', '') == 0.0\n",
    "assert lcs_ratio('foo', '') == 0.0\n",
    "assert lcs_ratio('foobar', 'foobar') == 1.0\n",
    "assert lcs_ratio('foo', 'bar') == 0.0\n",
    "assert lcs_ratio('word', 'deoxyribonucleic') == 0.25\n",
    "\n",
    "\n",
    "def consonant_skeleton(string, vowels='aeiouy'):\n",
    "    without_vowels = ''.join([char for char in string if char not in vowels])     \n",
    "    deduplicated_consonants = ''.join(char for char, _ in groupby(without_vowels))\n",
    "    return deduplicated_consonants\n",
    "\n",
    "assert consonant_skeleton('') == ''\n",
    "assert consonant_skeleton('aeio') == ''\n",
    "assert consonant_skeleton('foobar') == 'fbr'\n",
    "assert consonant_skeleton('ffoobbar') == 'fbr'\n",
    "assert consonant_skeleton('barfoobar') == 'brfbr'\n",
    "\n",
    "\n",
    "def ibm_similarity(string1, string2):\n",
    "    similarity = lcs_ratio(string1, string2) / (levenshtein (consonant_skeleton(string1), consonant_skeleton(string2)) + 1)\n",
    "    return similarity\n",
    "\n",
    "assert ibm_similarity('', '') == 0.0\n",
    "assert ibm_similarity('foobar', '') == 0.0\n",
    "assert ibm_similarity('foobar', 'foobar') == 1.0\n",
    "assert ibm_similarity('foo', 'bar') == 0.0\n",
    "assert ibm_similarity('word', 'deoxyribonucleic') == 0.03125\n",
    "assert ibm_similarity('foobar', 'aeiou') == 0.041666666666666664"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting the original and modernised tokens and types\n",
    "tmp_tokens_original = [token[0] for token in tokens if token[1].startswith('mein')]\n",
    "tmp_tokens_modernised = [token[1] for token in tokens if token[1].startswith('mein')]\n",
    "tmp_types_original = list(set(tmp_tokens_original))\n",
    "tmp_types_modernised = list(set(tmp_tokens_modernised))\n",
    "\n",
    "tmp_types_original_reshaped = np.array(tmp_types_original).reshape(-1,1)\n",
    "tmp_types_original_pairwise_distance_levenshtein = scipy.spatial.distance.pdist(tmp_types_original_reshaped, lambda x,y: levenshtein(str(x[0]),str(y[0])))\n",
    "tmp_types_original_pairwise_distance_jaro = scipy.spatial.distance.pdist(tmp_types_original_reshaped, lambda x,y: jaro(str(x[0]),str(y[0])))\n",
    "tmp_types_original_pairwise_distance_ibm = scipy.spatial.distance.pdist(tmp_types_original_reshaped, lambda x,y: ibm_similarity(str(x[0]),str(y[0])))\n",
    "\n",
    "\n",
    "tmp_original_distance_matrix_levenshtein = pandas.DataFrame(scipy.spatial.distance.squareform(tmp_types_original_pairwise_distance_levenshtein), index=tmp_types_original, columns=tmp_types_original)\n",
    "tmp_original_distance_matrix_jaro = pandas.DataFrame(scipy.spatial.distance.squareform(tmp_types_original_pairwise_distance_jaro), index=tmp_types_original, columns=tmp_types_original)\n",
    "tmp_original_distance_matrix_ibm = pandas.DataFrame(scipy.spatial.distance.squareform(tmp_types_original_pairwise_distance_ibm), index=tmp_types_original, columns=tmp_types_original)\n",
    "\n",
    "\n",
    "tmp_types_modernised_reshaped = np.array(tmp_types_modernised).reshape(-1,1)\n",
    "tmp_types_modernised_pairwise_distance_levenshtein = scipy.spatial.distance.pdist(tmp_types_modernised_reshaped, lambda x,y: levenshtein(str(x[0]),str(y[0])))\n",
    "tmp_types_modernised_pairwise_distance_jaro = scipy.spatial.distance.pdist(tmp_types_modernised_reshaped, lambda x,y: jaro(str(x[0]),str(y[0])))\n",
    "tmp_types_modernised_pairwise_distance_ibm = scipy.spatial.distance.pdist(tmp_types_modernised_reshaped, lambda x,y: ibm_similarity(str(x[0]),str(y[0])))\n",
    "\n",
    "tmp_modernised_distance_matrix_levenshtein = pandas.DataFrame(scipy.spatial.distance.squareform(tmp_types_modernised_pairwise_distance_levenshtein), index=tmp_types_modernised, columns=tmp_types_modernised)\n",
    "tmp_modernised_distance_matrix_jaro = pandas.DataFrame(scipy.spatial.distance.squareform(tmp_types_modernised_pairwise_distance_jaro), index=tmp_types_modernised, columns=tmp_types_modernised)\n",
    "tmp_modernised_distance_matrix_ibm = pandas.DataFrame(scipy.spatial.distance.squareform(tmp_types_modernised_pairwise_distance_ibm), index=tmp_types_modernised, columns=tmp_types_modernised)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_original_distance_matrix_levenshtein"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_original_distance_matrix_jaro"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tmp_original_distance_matrix_ibm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "types_original_reshaped = np.array(types_original).reshape(-1,1)\n",
    "types_original_pairwise_distance_levenshtein = scipy.spatial.distance.pdist(types_original_reshaped, lambda x,y: levenshtein(str(x[0]),str(y[0])))   \n",
    "types_original_pairwise_distance_jaro = scipy.spatial.distance.pdist(types_original_reshaped, lambda x,y: jaro(str(x[0]),str(y[0])))   \n",
    "types_original_pairwise_distance_ibm = scipy.spatial.distance.pdist(types_original_reshaped, lambda x,y: ibm_similarity(str(x[0]),str(y[0])))\n",
    "\n",
    "\n",
    "types_modernised_reshaped = np.array(types_modernised).reshape(-1,1)\n",
    "types_modernised_pairwise_distance_levenshtein = scipy.spatial.distance.pdist(types_modernised_reshaped, lambda x,y: levenshtein(str(x[0]),str(y[0]))) \n",
    "types_modernised_pairwise_distance_jaro = scipy.spatial.distance.pdist(types_modernised_reshaped, lambda x,y: jaro(str(x[0]),str(y[0])))\n",
    "types_modernised_pairwise_distance_ibm = scipy.spatial.distance.pdist(types_modernised_reshaped, lambda x,y: ibm_similarity(str(x[0]),str(y[0])))   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "# Transforming pairwise distances into a full similarity matrix\n",
    "original_distance_matrix_levenshtein = pandas.DataFrame(scipy.spatial.distance.squareform(types_original_pairwise_distance_levenshtein), index=types_original, columns=types_original)\n",
    "modernised_distance_matrix_levenshtein = pandas.DataFrame(scipy.spatial.distance.squareform(types_modernised_pairwise_distance_levenshtein), index=types_modernised, columns=types_modernised)\n",
    "\n",
    "original_distance_matrix_jaro = pandas.DataFrame(scipy.spatial.distance.squareform(types_original_pairwise_distance_jaro), index=types_original, columns=types_original)\n",
    "modernised_distance_matrix_jaro = pandas.DataFrame(scipy.spatial.distance.squareform(types_modernised_pairwise_distance_jaro), index=types_modernised, columns=types_modernised)\n",
    "\n",
    "original_distance_matrix_ibm = pandas.DataFrame(scipy.spatial.distance.squareform(types_original_pairwise_distance_ibm), index=types_original, columns=types_original)\n",
    "modernised_distance_matrix_ibm = pandas.DataFrame(scipy.spatial.distance.squareform(types_modernised_pairwise_distance_ibm), index=types_modernised, columns=types_modernised)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# PCA "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = sklearn.decomposition.PCA(n_components = 3)\n",
    "\n",
    "original_pca_lev = pca.fit(original_distance_matrix_levenshtein).transform(original_distance_matrix_levenshtein)\n",
    "modernised_pca_lev = pca.fit(modernised_distance_matrix_levenshtein).transform(modernised_distance_matrix_levenshtein)\n",
    "\n",
    "original_pca_jaro = pca.fit(original_distance_matrix_jaro).transform(original_distance_matrix_jaro)\n",
    "modernised_pca_jaro = pca.fit(modernised_distance_matrix_jaro).transform(modernised_distance_matrix_jaro)\n",
    "\n",
    "original_pca_ibm = pca.fit(original_distance_matrix_ibm).transform(original_distance_matrix_ibm)\n",
    "modernised_pca_ibm = pca.fit(modernised_distance_matrix_ibm).transform(modernised_distance_matrix_ibm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_pca_levenshtein_df = pandas.DataFrame()\n",
    "original_pca_levenshtein_df['pca-x-original'] = original_pca_lev[:,0]\n",
    "original_pca_levenshtein_df['pca-y-original'] = original_pca_lev[:,1]\n",
    "original_pca_levenshtein_df['pca-z-original'] = original_pca_lev[:,2]\n",
    "original_pca_levenshtein_df['token'] = original_distance_matrix_levenshtein.index\n",
    "\n",
    "modernised_pca_levenshtein_df = pandas.DataFrame()\n",
    "modernised_pca_levenshtein_df['pca-x-modernised'] = modernised_pca_lev[:,0]\n",
    "modernised_pca_levenshtein_df['pca-y-modernised'] = modernised_pca_lev[:,1]\n",
    "modernised_pca_levenshtein_df['pca-z-modernised'] = modernised_pca_lev[:,2]\n",
    "modernised_pca_levenshtein_df['token'] = modernised_distance_matrix_levenshtein.index\n",
    "\n",
    "original_pca_jaro_df = pandas.DataFrame()\n",
    "original_pca_jaro_df['pca-x-original'] = original_pca_jaro[:,0]\n",
    "original_pca_jaro_df['pca-y-original'] = original_pca_jaro[:,1]\n",
    "original_pca_jaro_df['pca-z-original'] = original_pca_jaro[:,2]\n",
    "original_pca_jaro_df['token'] = original_distance_matrix_jaro.index\n",
    "\n",
    "modernised_pca_jaro_df = pandas.DataFrame()\n",
    "modernised_pca_jaro_df['pca-x-modernised'] = modernised_pca_jaro[:,0]\n",
    "modernised_pca_jaro_df['pca-y-modernised'] = modernised_pca_jaro[:,1]\n",
    "modernised_pca_jaro_df['pca-z-modernised'] = modernised_pca_jaro[:,2]\n",
    "modernised_pca_jaro_df['token'] = modernised_distance_matrix_jaro.index\n",
    "\n",
    "original_pca_ibm_df = pandas.DataFrame()\n",
    "original_pca_ibm_df['pca-x-original'] = original_pca_ibm[:,0]\n",
    "original_pca_ibm_df['pca-y-original'] = original_pca_ibm[:,1]\n",
    "original_pca_ibm_df['pca-z-original'] = original_pca_ibm[:,2]\n",
    "original_pca_ibm_df['token'] = original_distance_matrix_ibm.index\n",
    "\n",
    "modernised_pca_ibm_df = pandas.DataFrame()\n",
    "modernised_pca_ibm_df['pca-x-modernised'] = modernised_pca_ibm[:,0]\n",
    "modernised_pca_ibm_df['pca-y-modernised'] = modernised_pca_ibm[:,1]\n",
    "modernised_pca_ibm_df['pca-z-modernised'] = modernised_pca_ibm[:,2]\n",
    "modernised_pca_ibm_df['token'] = modernised_distance_matrix_ibm.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=original_pca_levenshtein_df['pca-x-original'],\n",
    "    y=original_pca_levenshtein_df['pca-y-original'],\n",
    "    z=original_pca_levenshtein_df['pca-z-original'],\n",
    "    mode='markers',\n",
    "    text=original_pca_levenshtein_df['token'],\n",
    "    marker=dict(\n",
    "        size=2,\n",
    "        color='steelblue',\n",
    "        opacity=1\n",
    "    )\n",
    ")])\n",
    "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=modernised_pca_levenshtein_df['pca-x-modernised'],\n",
    "    y=modernised_pca_levenshtein_df['pca-y-modernised'],\n",
    "    z=modernised_pca_levenshtein_df['pca-z-modernised'],\n",
    "    mode='markers',\n",
    "    text=modernised_pca_levenshtein_df['token'],\n",
    "    marker=dict(\n",
    "        size=2,\n",
    "        color='skyblue',\n",
    "        opacity=1\n",
    "    )\n",
    ")])\n",
    "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=original_pca_jaro_df['pca-x-original'],\n",
    "    y=original_pca_jaro_df['pca-y-original'],\n",
    "    z=original_pca_jaro_df['pca-z-original'],\n",
    "    mode='markers',\n",
    "    text=original_pca_jaro_df['token'],\n",
    "    marker=dict(\n",
    "        size=2,\n",
    "        color='salmon',\n",
    "        opacity=1\n",
    "    )\n",
    ")])\n",
    "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=original_pca_ibm_df['pca-x-original'],\n",
    "    y=original_pca_ibm_df['pca-y-original'],\n",
    "    z=original_pca_ibm_df['pca-z-original'],\n",
    "    mode='markers',\n",
    "    text=original_pca_ibm_df['token'],\n",
    "    marker=dict(\n",
    "        size=2,\n",
    "        color='seagreen',\n",
    "        opacity=1\n",
    "    )\n",
    ")])\n",
    "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=modernised_pca_ibm_df['pca-x-modernised'],\n",
    "    y=modernised_pca_ibm_df['pca-y-modernised'],\n",
    "    z=modernised_pca_ibm_df['pca-z-modernised'],\n",
    "    mode='markers',\n",
    "    text=modernised_pca_ibm_df['token'],\n",
    "    marker=dict(\n",
    "        size=2,\n",
    "        color='darkgreen',\n",
    "        opacity=1\n",
    "    )\n",
    ")])\n",
    "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# UMAP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "\n",
    "original_similarity_embedded_umap_levenshtein = umap.UMAP(n_components=3).fit_transform(original_distance_matrix_levenshtein)\n",
    "modernised_similarity_embedded_umap_levenshtein = umap.UMAP(n_components=3).fit_transform(modernised_distance_matrix_levenshtein)\n",
    "\n",
    "original_similarity_embedded_umap_jaro = umap.UMAP(n_components=3).fit_transform(original_distance_matrix_jaro)\n",
    "modernised_similarity_embedded_umap_jaro = umap.UMAP(n_components=3).fit_transform(modernised_distance_matrix_jaro)\n",
    "\n",
    "original_similarity_embedded_umap_ibm = umap.UMAP(n_components=3).fit_transform(original_distance_matrix_ibm)\n",
    "modernised_similarity_embedded_umap_ibm = umap.UMAP(n_components=3).fit_transform(modernised_distance_matrix_ibm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_umap_levenshtein = pandas.DataFrame()\n",
    "original_umap_levenshtein['umap-x-original'] = original_similarity_embedded_umap_levenshtein[:,0]\n",
    "original_umap_levenshtein['umap-y-original'] = original_similarity_embedded_umap_levenshtein[:,1]\n",
    "original_umap_levenshtein['umap-z-original'] = original_similarity_embedded_umap_levenshtein[:,2]\n",
    "original_umap_levenshtein['token'] = original_distance_matrix_levenshtein.index\n",
    "\n",
    "modernised_umap_levenshtein = pandas.DataFrame()\n",
    "modernised_umap_levenshtein['umap-x-modernised'] = modernised_similarity_embedded_umap_levenshtein[:,0]\n",
    "modernised_umap_levenshtein['umap-y-modernised'] = modernised_similarity_embedded_umap_levenshtein[:,1]\n",
    "modernised_umap_levenshtein['umap-z-modernised'] = modernised_similarity_embedded_umap_levenshtein[:,2]\n",
    "modernised_umap_levenshtein['token'] = modernised_distance_matrix_levenshtein.index\n",
    "\n",
    "original_umap_jaro = pandas.DataFrame()\n",
    "original_umap_jaro['umap-x-original'] = original_similarity_embedded_umap_jaro[:,0]\n",
    "original_umap_jaro['umap-y-original'] = original_similarity_embedded_umap_jaro[:,1]\n",
    "original_umap_jaro['umap-z-original'] = original_similarity_embedded_umap_jaro[:,2]\n",
    "original_umap_jaro['token'] = original_distance_matrix_jaro.index\n",
    "\n",
    "modernised_umap_jaro = pandas.DataFrame()\n",
    "modernised_umap_jaro['umap-x-modernised'] = modernised_similarity_embedded_umap_jaro[:,0]\n",
    "modernised_umap_jaro['umap-y-modernised'] = modernised_similarity_embedded_umap_jaro[:,1]\n",
    "modernised_umap_jaro['umap-z-modernised'] = modernised_similarity_embedded_umap_jaro[:,2]\n",
    "modernised_umap_jaro['token'] = modernised_distance_matrix_jaro.index\n",
    "\n",
    "original_umap_ibm = pandas.DataFrame()\n",
    "original_umap_ibm['umap-x-original'] = original_similarity_embedded_umap_ibm[:,0]\n",
    "original_umap_ibm['umap-y-original'] = original_similarity_embedded_umap_ibm[:,1]\n",
    "original_umap_ibm['umap-z-original'] = original_similarity_embedded_umap_ibm[:,2]\n",
    "original_umap_ibm['token'] = original_distance_matrix_ibm.index\n",
    "\n",
    "modernised_umap_ibm = pandas.DataFrame()\n",
    "modernised_umap_ibm['umap-x-modernised'] = modernised_similarity_embedded_umap_ibm[:,0]\n",
    "modernised_umap_ibm['umap-y-modernised'] = modernised_similarity_embedded_umap_ibm[:,1]\n",
    "modernised_umap_ibm['umap-z-modernised'] = modernised_similarity_embedded_umap_ibm[:,2]\n",
    "modernised_umap_ibm['token'] = modernised_distance_matrix_ibm.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=original_umap_levenshtein['umap-x-original'],\n",
    "    y=original_umap_levenshtein['umap-y-original'],\n",
    "    z=original_umap_levenshtein['umap-z-original'],\n",
    "    mode='markers',\n",
    "    text=original_umap_levenshtein['token'],\n",
    "    marker=dict(\n",
    "        size=2,\n",
    "        color='steelblue',\n",
    "        opacity=1\n",
    "    )\n",
    ")])\n",
    "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=modernised_umap_levenshtein['umap-x-modernised'],\n",
    "    y=modernised_umap_levenshtein['umap-y-modernised'],\n",
    "    z=modernised_umap_levenshtein['umap-z-modernised'],\n",
    "    mode='markers',\n",
    "    text=modernised_umap_levenshtein['token'],\n",
    "    marker=dict(\n",
    "        size=2,\n",
    "        color='skyblue',\n",
    "        opacity=1\n",
    "    )\n",
    ")])\n",
    "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=original_umap_jaro['umap-x-original'],\n",
    "    y=original_umap_jaro['umap-y-original'],\n",
    "    z=original_umap_jaro['umap-z-original'],\n",
    "    mode='markers',\n",
    "    text=original_umap_jaro['token'],\n",
    "    marker=dict(\n",
    "        size=2,\n",
    "        color='salmon',\n",
    "        opacity=1\n",
    "    )\n",
    ")])\n",
    "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=modernised_umap_jaro['umap-x-modernised'],\n",
    "    y=modernised_umap_jaro['umap-y-modernised'],\n",
    "    z=modernised_umap_jaro['umap-z-modernised'],\n",
    "    mode='markers',\n",
    "    text=modernised_umap_jaro['token'],\n",
    "    marker=dict(\n",
    "        size=2,\n",
    "        color='orange',\n",
    "        opacity=1\n",
    "    )\n",
    ")])\n",
    "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=original_umap_ibm['umap-x-original'],\n",
    "    y=original_umap_ibm['umap-y-original'],\n",
    "    z=original_umap_ibm['umap-z-original'],\n",
    "    mode='markers',\n",
    "    text=original_umap_ibm['token'],\n",
    "    marker=dict(\n",
    "        size=2,\n",
    "        color='seagreen',\n",
    "        opacity=1\n",
    "    )\n",
    ")])\n",
    "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=modernised_umap_ibm['umap-x-modernised'],\n",
    "    y=modernised_umap_ibm['umap-y-modernised'],\n",
    "    z=modernised_umap_ibm['umap-z-modernised'],\n",
    "    mode='markers',\n",
    "    text=modernised_umap_ibm['token'],\n",
    "    marker=dict(\n",
    "        size=2,\n",
    "        color='darkgreen',\n",
    "        opacity=1\n",
    "    )\n",
    ")])\n",
    "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# t-SNE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%time\n",
    "original_similarity_embedded_tsne_levenshtein = sklearn.manifold.TSNE(n_components=3).fit_transform(original_distance_matrix_levenshtein)\n",
    "modernised_similarity_embedded_tsne_levenshtein = sklearn.manifold.TSNE(n_components=3).fit_transform(modernised_distance_matrix_levenshtein)\n",
    "\n",
    "original_similarity_embedded_tsne_jaro = sklearn.manifold.TSNE(n_components=3).fit_transform(original_distance_matrix_jaro)\n",
    "modernised_similarity_embedded_tsne_jaro = sklearn.manifold.TSNE(n_components=3).fit_transform(modernised_distance_matrix_jaro)\n",
    "\n",
    "original_similarity_embedded_tsne_ibm = sklearn.manifold.TSNE(n_components=3).fit_transform(original_distance_matrix_ibm)\n",
    "modernised_similarity_embedded_tsne_ibm = sklearn.manifold.TSNE(n_components=3).fit_transform(modernised_distance_matrix_ibm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_tsne_levenshtein = pandas.DataFrame()\n",
    "original_tsne_levenshtein['tsne-x-original'] = original_similarity_embedded_tsne_levenshtein[:,0]\n",
    "original_tsne_levenshtein['tsne-y-original'] = original_similarity_embedded_tsne_levenshtein[:,1]\n",
    "original_tsne_levenshtein['tsne-z-original'] = original_similarity_embedded_tsne_levenshtein[:,2]\n",
    "original_tsne_levenshtein['token'] = original_distance_matrix_levenshtein.index\n",
    "\n",
    "modernised_tsne_levenshtein = pandas.DataFrame()\n",
    "modernised_tsne_levenshtein['tsne-x-modernised'] = modernised_similarity_embedded_tsne_levenshtein[:,0]\n",
    "modernised_tsne_levenshtein['tsne-y-modernised'] = modernised_similarity_embedded_tsne_levenshtein[:,1]\n",
    "modernised_tsne_levenshtein['tsne-z-modernised'] = modernised_similarity_embedded_tsne_levenshtein[:,2]\n",
    "modernised_tsne_levenshtein['token'] = modernised_distance_matrix_levenshtein.index\n",
    "\n",
    "original_tsne_jaro = pandas.DataFrame()\n",
    "original_tsne_jaro['tsne-x-original'] = original_similarity_embedded_tsne_jaro[:,0]\n",
    "original_tsne_jaro['tsne-y-original'] = original_similarity_embedded_tsne_jaro[:,1]\n",
    "original_tsne_jaro['tsne-z-original'] = original_similarity_embedded_tsne_jaro[:,2]\n",
    "original_tsne_jaro['token'] = original_distance_matrix_jaro.index\n",
    "\n",
    "modernised_tsne_jaro = pandas.DataFrame()\n",
    "modernised_tsne_jaro['tsne-x-modernised'] = modernised_similarity_embedded_tsne_jaro[:,0]\n",
    "modernised_tsne_jaro['tsne-y-modernised'] = modernised_similarity_embedded_tsne_jaro[:,1]\n",
    "modernised_tsne_jaro['tsne-z-modernised'] = modernised_similarity_embedded_tsne_jaro[:,2]\n",
    "modernised_tsne_jaro['token'] = modernised_distance_matrix_jaro.index\n",
    "\n",
    "original_tsne_ibm = pandas.DataFrame()\n",
    "original_tsne_ibm['tsne-x-original'] = original_similarity_embedded_tsne_ibm[:,0]\n",
    "original_tsne_ibm['tsne-y-original'] = original_similarity_embedded_tsne_ibm[:,1]\n",
    "original_tsne_ibm['tsne-z-original'] = original_similarity_embedded_tsne_ibm[:,2]\n",
    "original_tsne_ibm['token'] = original_distance_matrix_ibm.index\n",
    "\n",
    "modernised_tsne_ibm = pandas.DataFrame()\n",
    "modernised_tsne_ibm['tsne-x-modernised'] = modernised_similarity_embedded_tsne_ibm[:,0]\n",
    "modernised_tsne_ibm['tsne-y-modernised'] = modernised_similarity_embedded_tsne_ibm[:,1]\n",
    "modernised_tsne_ibm['tsne-z-modernised'] = modernised_similarity_embedded_tsne_ibm[:,2]\n",
    "modernised_tsne_ibm['token'] = modernised_distance_matrix_ibm.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=original_tsne_levenshtein['tsne-x-original'],\n",
    "    y=original_tsne_levenshtein['tsne-y-original'],\n",
    "    z=original_tsne_levenshtein['tsne-z-original'],\n",
    "    mode='markers',\n",
    "    text=original_tsne_levenshtein['token'],\n",
    "    marker=dict(\n",
    "        size=2,\n",
    "        color='steelblue',\n",
    "        opacity=1\n",
    "    )\n",
    ")])\n",
    "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=modernised_tsne_levenshtein['tsne-x-modernised'],\n",
    "    y=modernised_tsne_levenshtein['tsne-y-modernised'],\n",
    "    z=modernised_tsne_levenshtein['tsne-z-modernised'],\n",
    "    mode='markers',\n",
    "    text=modernised_umap_levenshtein['token'],\n",
    "    marker=dict(\n",
    "        size=2,\n",
    "        color='skyblue',\n",
    "        opacity=1\n",
    "    )\n",
    ")])\n",
    "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=original_tsne_jaro['tsne-x-original'],\n",
    "    y=original_tsne_jaro['tsne-y-original'],\n",
    "    z=original_tsne_jaro['tsne-z-original'],\n",
    "    mode='markers',\n",
    "    text=original_tsne_jaro['token'],\n",
    "    marker=dict(\n",
    "        size=2,\n",
    "        color='salmon',\n",
    "        opacity=1\n",
    "    )\n",
    ")])\n",
    "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=modernised_tsne_jaro['tsne-x-modernised'],\n",
    "    y=modernised_tsne_jaro['tsne-y-modernised'],\n",
    "    z=modernised_tsne_jaro['tsne-z-modernised'],\n",
    "    mode='markers',\n",
    "    text=modernised_tsne_jaro['token'],\n",
    "    marker=dict(\n",
    "        size=2,\n",
    "        color='orange',\n",
    "        opacity=1\n",
    "    )\n",
    ")])\n",
    "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=original_tsne_ibm['tsne-x-original'],\n",
    "    y=original_tsne_ibm['tsne-y-original'],\n",
    "    z=original_tsne_ibm['tsne-z-original'],\n",
    "    mode='markers',\n",
    "    text=original_tsne_ibm['token'],\n",
    "    marker=dict(\n",
    "        size=2,\n",
    "        color='seagreen',\n",
    "        opacity=1\n",
    "    )\n",
    ")])\n",
    "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = go.Figure(data=[go.Scatter3d(\n",
    "    x=modernised_tsne_ibm['tsne-x-modernised'],\n",
    "    y=modernised_tsne_ibm['tsne-y-modernised'],\n",
    "    z=modernised_tsne_ibm['tsne-z-modernised'],\n",
    "    mode='markers',\n",
    "    text=modernised_tsne_ibm['token'],\n",
    "    marker=dict(\n",
    "        size=2,\n",
    "        color='darkgreen',\n",
    "        opacity=1\n",
    "    )\n",
    ")])\n",
    "fig.update_layout(margin=dict(l=0, r=0, b=0, t=0))\n",
    "fig.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
